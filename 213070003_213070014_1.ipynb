{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**EE769 Introduction to Machine Learning**\n",
        "\n",
        "#Assignment 1: Gradient Descent, Linear Regression, and Regularization\n",
        "\n",
        "\n",
        "**Template and Instructions**\n",
        "\n",
        "\n",
        "\n",
        "1. Up to two people can team up, but only one should submit, and both should understand the entire code.\n",
        "2. Every line of code should end in a comment explaining the line\n",
        "3. It is recommended to solve the assignment in Google Colab.\n",
        "Write your roll no.s separated by commas here: 213070003, 213070014\n",
        "4. Write your names here: Shivam Ashish Patil, Ram Akshayver Pal\n",
        "5. There are two parts to the assignment. In the Part 1, the code format has to be strictly followed to enable auto-grading. In the second part, you can be creative.\n",
        "6. **You can discuss with other groups or refer to the internet without being penalized, but you cannot copy their code and modify it. Write every line of code and comment on your own.**\n",
        "\n"
      ],
      "metadata": {
        "id": "Vl8EigX3osrA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "2c8d558bf9a7a47ea4bf343fa6fe9efb",
          "grade": false,
          "grade_id": "Title",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "pyC6rfqZokyx"
      },
      "source": [
        "#**Part 1 begins ...**\n",
        "**Instructions to be strictly followed:**\n",
        "\n",
        "1. Do not add any code cells or markdown cells until the end of this part. Especially, do not change the blocks that say \"TEST CASES, DO NOT CHANGE\"\n",
        "2. In all other cells only add code where it says \"CODE HERE\".\n",
        "3. If you encounter any raise NotImplementedError() calls you may comment them out.\n",
        "\n",
        "We cannot ensure correct grading if you change anything else, and you may be penalised for not following these instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Statements"
      ],
      "metadata": {
        "id": "Fuh-16Vfrtp7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fe70877a859ee0a10e9d591778022f8a",
          "grade": false,
          "grade_id": "Import_Statements",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "wGY8PStloky3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e36a214573fc40f26b45e72215d61375",
          "grade": false,
          "grade_id": "Normalize_Title",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "y3pISCproky5"
      },
      "source": [
        "## Normalize function \n",
        "\n",
        "Add your code in the cell below to normalize the independent variables, making them zero mean and unit variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0039f4480dfc6d62a548d976991c3a44",
          "grade": false,
          "grade_id": "Normalize_Function",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "rS3upFWtoky5"
      },
      "outputs": [],
      "source": [
        "def Normalize(X): # Output should be a normalized data matrix of the same dimension\n",
        "    '''\n",
        "    Normalize all columns of X using mean and standard deviation\n",
        "    '''\n",
        "    # YOUR CODE HERE\n",
        "    normX = []  #Initialize the matrix normX\n",
        "    if(X.ndim == 1):  # If the input is an array then normalization can be done in a single step\n",
        "      normX = (X-np.mean(X))/np.std(X) #Normalize each value of the  array\n",
        "    if(X.ndim == 2):  # If the input is a matrix\n",
        "      cols = X.shape[1];  # Find the number of columns of matrix X\n",
        "      for i in range(0,cols): # iterate through each column and normalize it\n",
        "        normX.append((X[:,i]-np.mean(X[:,i]))/np.std(X[:,i])) #Normalize each value of the  array and append to the \n",
        "    return np.transpose(normX) #return the transpose of the normalized matrix to match it with given matrix in test case\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7797dd606a68f028c945acd08850d108",
          "grade": true,
          "grade_id": "Normalize_Test",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ygO-K7bzoky6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 - 1 dimensional array'''\n",
        "#X=np.array([[1,2,3],[3,4,5],[7,8,9]])\n",
        "X1=np.array([1,2,3])\n",
        "np.testing.assert_array_almost_equal(Normalize(X1),np.array([-1.224,  0.      ,  1.224]),decimal=3)\n",
        "''' case 2 - 2 dimensional array'''\n",
        "X2=np.array([[4,7,6],[3,8,9],[5,11,10]])\n",
        "np.testing.assert_array_almost_equal(Normalize(X2),np.array([[ 0.  , -0.980581, -1.372813],[-1.224745, -0.392232,  0.392232],[ 1.224745,  1.372813,  0.980581]]))\n",
        "''' case 3 - 1 dimensional array with float'''\n",
        "X3=np.array([5.5,6.7,3.2,6.7])\n",
        "np.testing.assert_array_almost_equal(Normalize(X3),np.array([-0.017,  0.822, -1.627,  0.822]),decimal=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccow4yKXoky7"
      },
      "source": [
        "## Prediction Function\n",
        "\n",
        "Given X and w, compute the predicted output. Do not forget to add 1's in X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7b715eb6b4f2b77697550a46e173159a",
          "grade": false,
          "grade_id": "Prediction",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "3PRnu4F1oky7"
      },
      "outputs": [],
      "source": [
        "def Prediction (X, w): # Output should be a prediction vector y\n",
        "    '''\n",
        "    Compute Prediction given an input data matrix X and weight vector w. Output y = [X 1]w where 1 is a vector of all 1s \n",
        "    '''\n",
        "    # YOUR CODE HERE\n",
        "    X = np.c_[X,np.ones(X.shape[0])]  #Append ones to each row of X\n",
        "    pred = np.dot(X,np.transpose(w)) # To compute the prediction multiply X*transpose(w)\n",
        "    return pred #return the predicted value\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "741f088432fb2ac3c49d3c9711d5c9c5",
          "grade": true,
          "grade_id": "PredictionTest",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7vDdDzS4oky8"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 - Known input output matrix and weights 1'''\n",
        "X1 = np.array([[3,2],[1,1]])\n",
        "w1 = np.array([2,1,1]) \n",
        "np.testing.assert_array_equal(Prediction(X1,w1),np.array([9,4]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bb888c2310846a4ec20a151ff4b44291",
          "grade": false,
          "grade_id": "cell-6fda2832d5967072",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "CE6c5oM2oky9"
      },
      "source": [
        "## Loss Functions\n",
        "\n",
        "Code the four  loss functions:\n",
        "\n",
        "1. MSE loss is only for the error\n",
        "2. MAE loss is only for the error\n",
        "3. L2 loss is for MSE and L2 regularization, and can call MSE loss\n",
        "4. L1 loss is for MSE and L1 regularization, and can call MSE loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "834438a2ea2e2b52359b9620e36d82b2",
          "grade": false,
          "grade_id": "MSE_Loss",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Vx4oUdwRoky-"
      },
      "outputs": [],
      "source": [
        "def MSE_Loss (X, t, w, lamda =0): # Ouput should be a single number\n",
        "    '''\n",
        "    lamda=0 is a default argument to prevent errors if you pass lamda to a function that doesn't need it by mistake. \n",
        "    This allows us to call all loss functions with the same input format.\n",
        "    \n",
        "    You are encouraged read about default arguments by yourself online if you're not familiar.\n",
        "    '''\n",
        "    # YOUR CODE HERE\n",
        "    pred = Prediction(X,w); # Using the Prediction() function defined above find the prediction for given X\n",
        "    MSEerror = np.sum(np.square(pred-t))/len(t);  # Find the mean square error for each element of predicted array pred and take the mean square error \n",
        "    return MSEerror # Return the MSE error \n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "923a1372a401b41d6ef6b0749a49ff66",
          "grade": true,
          "grade_id": "MSE_Loss_Test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "beahjBNooky-"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_almost_equal(MSE_Loss(X,t,w),0.53,decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a6bc90c02aba76b8ca4072b0b5655560",
          "grade": false,
          "grade_id": "MAE_Loss",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "d6Pbd2AToky_"
      },
      "outputs": [],
      "source": [
        "def MAE_Loss (X, t, w, lamda = 0): # Output should be a single number\n",
        "    # YOUR CODE HERE\n",
        "    pred = Prediction(X,w)  # Using the Prediction() function defined above find the prediction for given input X\n",
        "    MAE_error = np.sum(abs(pred-t))/len(t)  #Find the absolute difference between predicted and true values then take their squares and divide by length of array t to get mean absolute error \n",
        "    return MAE_error #Return the error value\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f11d5fde7220893a9809f2954d18c5e5",
          "grade": true,
          "grade_id": "MAE_Loss_Test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "3IRXwTLwoky_"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_almost_equal(MAE_Loss(X,t,w),0.700,decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8cbed9318984e9fb83254ad57d06436e",
          "grade": false,
          "grade_id": "L2_Loss",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "GJcMY6bPokzA"
      },
      "outputs": [],
      "source": [
        "def L2_Loss (X, t, w, lamda): # Output should be a single number\n",
        "    ''' Need to specify what inputs are'''\n",
        "    # YOUR CODE HERE\n",
        "    pred = Prediction(X,w)  # Using the Prediction() function defined above find the prediction for given input X\n",
        "    L2_error = np.sum(np.square(pred-t))/len(t) + np.sqrt(np.sum(np.square(w[:-1])))*lamda\n",
        "    #First find squared error between prediction and actual value then sum all elements in the resultant array\n",
        "    #Add the L2 norm of weight array w exclude the last 1 in w\n",
        "    return L2_error # Return L2 error\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a5a409056f6797cdf8cbfab61b138c37",
          "grade": true,
          "grade_id": "L2_Loss_Test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "DQJBvFVnokzA"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_almost_equal(L2_Loss(X,t,w,0.5),1.675,decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bb055d3436a79fb3acb7535956f57466",
          "grade": false,
          "grade_id": "L1_Loss",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "1YwydMcAokzA"
      },
      "outputs": [],
      "source": [
        "def L1_Loss (X, t, w, lamda): # Output should be a single number\n",
        "    # YOUR CODE HERE\n",
        "    pred = Prediction(X,w)  # Using the Prediction() function defined above find the prediction for given input X\n",
        "    L1_error = np.sum(np.square(pred-t))/len(t) + np.sum(np.abs(w[:-1]))*lamda\n",
        "    #First find squared error between prediction and actual value then sum all elements in the resultant array\n",
        "    #Add the L1 norm of weight array w exclude the last 1 in w    \n",
        "    return L1_error\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "40224dd69dd8e6499a67271c33701bf4",
          "grade": true,
          "grade_id": "L1_Loss_Test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "IYLTEnR5okzB"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_almost_equal(L1_Loss(X,t,w,0.5),2.280,decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b6143269d14fa4e9b9a54a90f229620c",
          "grade": false,
          "grade_id": "NRMSE_Loss",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "GgsKvizNokzB"
      },
      "outputs": [],
      "source": [
        "def NRMSE_Loss (X, t, w): # Output should be a single number\n",
        "    # YOUR CODE HERE\n",
        "    pred = Prediction(X,w)  # Using the Prediction() function defined above find the prediction for given input X\n",
        "    RMSE = np.sqrt(np.sum(np.square(pred-t))/len(t))  \n",
        "    # RMSE is the root mean square error of predicted-actual value\n",
        "    NRMSE = RMSE/np.std(t)  #We divide the RMSE by std. deviation of actual values to obtain normalized RMSE\n",
        "    return NRMSE  #Return the NRMSE\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "06456562aa2ed36b11c7d40c52610133",
          "grade": true,
          "grade_id": "NRMSE_Loss_Test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "A15tcCFqokzB"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' Test case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_almost_equal(NRMSE_Loss(X,t,w),0.970,decimal=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "32344ab855de7c731a225d416924e47d",
          "grade": false,
          "grade_id": "Gradient_Title",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "zAJLKJNNokzC"
      },
      "source": [
        "## Gradient function\n",
        "Each Loss function will have its own gradient function:\n",
        "\n",
        "1. MSE gradient is only for the error\n",
        "2. MAE gradient is only for the error\n",
        "3. L2 gradient is for MSE and L2 regularization, and can call MSE gradient\n",
        "4. L1 gradient is for MSE and L1 regularization, and can call MSE gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c1c5a97c25a41dac499e5c245f9166b7",
          "grade": false,
          "grade_id": "MSE_Gradient",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "BZpqHWhBokzC"
      },
      "outputs": [],
      "source": [
        "def MSE_Gradient (X, t, w, lamda=0):\n",
        "    # YOUR CODE HERE\n",
        "    pred = Prediction(X,w)  # Using the Prediction() function defined above find the prediction for given input X\n",
        "    error = pred-t  # Error = predicted output-actual output\n",
        "    X = np.c_[X,np.ones(X.shape[0])]  #Append ones to each row of X\n",
        "    gradient = (2/len(t))*np.dot(np.transpose(X),error) #Find the gradient as derivative of MSE_Loss function \n",
        "    return gradient #return gradient\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d61466927592a8776a8bfa688472bad4",
          "grade": true,
          "grade_id": "MSE_Gradient_Test",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "eLjolBskokzC"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_array_almost_equal(MSE_Gradient(X,t,w),np.array([2.55, 2.94, 2.9 , 0.4 ]),decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3d7fb24daaa75279588b80e4a10cc8c6",
          "grade": false,
          "grade_id": "MAE_Gradient",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "YFF1-wxfokzD"
      },
      "outputs": [],
      "source": [
        "def MAE_Gradient (X, t, w, lamda=0): # Output should have the same size as w\n",
        "    # YOUR CODE HERE\n",
        "    pred = Prediction(X,w)  # Using the Prediction() function defined above find the prediction for given input X\n",
        "    X = np.c_[X,np.ones(X.shape[0])]  #Append ones to each row of X\n",
        "    gradient = (1/len(t))*np.dot(np.transpose(X),np.divide(pred-t,np.abs(pred-t))) #This formula can be obtained if we apply partial derivative to MAE_Error function\n",
        "    return gradient #return the calculated gradient\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e1d418bf5351112ae8716877f8bb6359",
          "grade": true,
          "grade_id": "MAE_Gradient_Test",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1bBoPfiMokzD"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_array_almost_equal(MAE_Gradient(X,t,w),np.array([0.75,  0.3 ,  0.5 , 0.]),decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bee96dccc2e2096ed187b41cb4e81f4e",
          "grade": false,
          "grade_id": "L2_Gradient",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "qmlR91dzokzD"
      },
      "outputs": [],
      "source": [
        "def L2_Gradient (X, t, w, lamda): # Output should have the same size as w\n",
        "    # YOUR CODE HERE\n",
        "    pred = Prediction(X,w)  # Using the Prediction() function defined above find the prediction for given input X\n",
        "    X = np.c_[X,np.ones(X.shape[0])]  #Append ones to each row of X\n",
        "    w[len(w)-1] = 0 #Make the last element i.e. 1 equal to 0 as it is not used in gradient calculation\n",
        "    gradient = (2/len(t))*np.dot(np.transpose(X),pred-t) + lamda*w/np.sqrt(np.sum(np.square(w[:-1]))) #Compute the gradient, this result is obtained by differentiation of L2_loss function\n",
        "    return gradient #Return radient function\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f292b42c3389b24e369234a7210b87bb",
          "grade": true,
          "grade_id": "L2_Gradient_Test",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "6lxwah-zokzD"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_array_almost_equal(L2_Gradient(X,t,w,0.5),np.array([2.986, 2.721, 3.009 , 0.4 ]),decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5bff06a852c13effc51014992ffce310",
          "grade": false,
          "grade_id": "L1_Gradient",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "a6P-GUZ0okzE"
      },
      "outputs": [],
      "source": [
        "def L1_Gradient (X, t, w, lamda): # Output should have the same size as w\n",
        "    # YOUR CODE HERE\n",
        "    pred = Prediction(X,w)  # Using the Prediction() function defined above find the prediction for given input X\n",
        "    X = np.c_[X,np.ones(X.shape[0])]  #Append ones to each row of X\n",
        "    #w[len(w)-1] = 0 #Make the last element i.e. 1 equal to 0 as it is not used in gradient calculation\n",
        "    gradient = (2/len(t))*np.dot(np.transpose(X),pred-t) + lamda*np.divide(w,np.abs(w)) #This formula for gradient can be obtained by differentiating L1_Gradient\n",
        "    dotProd = (2/len(t))*np.dot(np.transpose(X),pred-t) #matrix multiplication of transpose(X)*(pred-t) useful for further calculations\n",
        "    gradient[len(w)-1] = dotProd[len(w)-1]  # Last element of gradient vector should not include the w array's contribuation\n",
        "    return gradient #Return the gradient\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9097b61320e470f429a9f46c7da0b219",
          "grade": true,
          "grade_id": "L1_Gradient_Test",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "dITScW5pokzE"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_array_almost_equal(L1_Gradient(X,t,w,0.5),np.array([3.05, 2.44, 3.4 , 0.4 ]),decimal=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1980a2f831b5e1ddc9b510c22ef502c7",
          "grade": false,
          "grade_id": "Gradient_Desc_Title",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "4ZsJWrKWokzE"
      },
      "source": [
        "## Gradient Descent Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "78cdd5ffa4590c10e19281722ccd537f",
          "grade": false,
          "grade_id": "Gradient_Descent",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "WRE6NRLt8u8r"
      },
      "outputs": [],
      "source": [
        "def Gradient_Descent (X, X_val, t, t_val, w, lamda, max_iter, epsilon, lr, lossfunc, gradfunc): # See output format in 'return' statement\n",
        "    # YOUR CODE HERE\n",
        "    loss = np.zeros(max_iter)  # Define an array for storing L2 loss for each updated w vector in below for loop\n",
        "    for i in range(max_iter):  # For loop to iterate through the maximum no of iterations for gradient descent\n",
        "      grad = gradfunc(X, t, w, lamda)  #Find the gradient vector for each iteration\n",
        "      temp_w = w -  lr*grad  #All elements of w are updated in each iteration\n",
        "      loss[i] =  lossfunc(X, t, w, lamda) #L2_Loss function for w in current iteration\n",
        "      if (i>0 and abs(loss[i]-loss[i-1])<epsilon): #Stop gradient descent when maxiterations are over or when consecutive losses are less than epsilon\n",
        "        break;\n",
        "      w = temp_w #Update w vector\n",
        "    w_final = w  \n",
        "    train_loss_final = lossfunc(X, t, w_final, lamda)  #find training MSE using given loss function\n",
        "    validation_loss_final = lossfunc(X_val,t_val,w_final,lamda) #find validation MSE using given loss function\n",
        "    validation_NRMSE = np.sqrt(validation_loss_final)/np.std(t_val) # Validation NRMSE = RMSE/(std deviation)\n",
        "    return w_final, train_loss_final, validation_loss_final, validation_NRMSE #You should return variables structured like this.\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "15a67336bed20a51f33820bf615186e8",
          "grade": true,
          "grade_id": "Gradient_Check",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "wFgUYUjX8u8s"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "X=np.array([[23,24],[1,2]])\n",
        "t=np.array([4,5])\n",
        "X_val=np.array([[3,4],[5,6]])\n",
        "t_val=np.array([3,4])\n",
        "w=np.array([3,2,1])\n",
        "results =Gradient_Descent (X, X_val, t, t_val, w, 0.1, 100, 1e-10, 1e-5, L2_Loss,L2_Gradient) \n",
        "np.testing.assert_allclose([results[1]],[697.919],rtol =0.05)\n",
        "np.testing.assert_allclose([results[2]],[20],atol=5) # we expect around 17.5  but some students got 24 which we will also accept\n",
        "#Instructor Values of results[1] and results [2] are 697.919 and 17.512 respectively"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "454ff10ef4f228e28cf5dc32b02a46b0",
          "grade": false,
          "grade_id": "PseudoInvTitle",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "M75l_wFCokzF"
      },
      "source": [
        "## Pseudo Inverse Method\n",
        "\n",
        "You have to implement a slightly more advanced version, with L2 penalty:\n",
        "\n",
        "w = (X' X + lambda I)^(-1) X' t.\n",
        "\n",
        "See, for example: Section 2 of https://web.mit.edu/zoya/www/linearRegression.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cb4fed33ae855881d92f2d0bee916fd7",
          "grade": false,
          "grade_id": "PseudoInv",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "7ZAU-Td1okzF"
      },
      "outputs": [],
      "source": [
        "def Pseudo_Inverse (X, t, lamda): # Output should be weight vector\n",
        "    # YOUR CODE HERE\n",
        "    X = np.c_[X,np.ones(X.shape[0])]  #Append ones to each row of X\n",
        "    w = np.dot(np.linalg.inv(np.dot(np.transpose(X),X) + lamda*np.identity(X.shape[1])),np.dot(np.transpose(X),t)) \n",
        "    return w  #return the parameter array\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a5178b8280650ed5d1d55dc6bbb38a29",
          "grade": true,
          "grade_id": "PseudoInvTest",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "50jkxZybokzF"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 - other data'''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "np.testing.assert_array_almost_equal(Pseudo_Inverse(X,t,0.5),np.array([ 0.491,  0.183,  0.319, -0.002]),decimal=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save the code above this as a RollNo1_RollNo2_1.py file after running the test blocks to make sure there are no errors."
      ],
      "metadata": {
        "id": "vwFm7JnBXDff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**... Part 1 ends**\n",
        "Below this you be more creative. Just comment out the lines where you save files (e.g. test predictions)."
      ],
      "metadata": {
        "id": "AboSSuSpw3RB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Part 2 begins ...**\n",
        "\n",
        "**Instructions to be loosely followed (except number 8):**\n",
        "\n",
        "1. Add more code and text cells between this and the last cell.\n",
        "2. Read training data from: https://www.ee.iitb.ac.in/~asethi/Dump/TempTrain.csv only. Do not use a local copy of the dataset.\n",
        "3. Find the best lamda for **MSE+lamda*L2(w)** loss function. Plot training and validation RMSE vs. 1/lamda (1/lamda represents model complexity). Print weights, validation RMSE, validation NMSE for the best lamda.\n",
        "4. Find the best lamda for **MSE+lamda*L1(w)** loss function. Plot training and validation RMSE vs. 1/lamda (1/lamda represents model complexity). Print weights, validation RMSE, validation NMSE for the best lamda.\n",
        "5. Find the best lamda for the **pseudo-inv method**. Plot training and validation RMSE vs. 1/lamda (1/lamda represents model complexity). Print weights, validation RMSE, validation NMSE for the best lamda.\n",
        "6. Write your observations and conclusions.\n",
        "7. Read test data from: https://www.ee.iitb.ac.in/~asethi/Dump/TempTest.csv only. Do not use a local copy of the dataset. Predict its dependent (missing last column) using the model with the lowest MSE, RMSE, or NMSE. Save it as a file RollNo1_RollNo2_1.csv.\n",
        "8. **Disable the prediction csv file saving statement and submit this entire .ipynb file (part 1 and part 2), .py file (part 1 only), and .csv file as a single RollNo1_RollNo2_1.zip file.**\n"
      ],
      "metadata": {
        "id": "wNxr2zopT59T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://www.ee.iitb.ac.in/~asethi/Dump/TempTrain.csv')"
      ],
      "metadata": {
        "id": "XV7L2S7nqU0i"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate input matrix and output matrix\n",
        "#Referred from: https://www.askpython.com/python/examples/split-data-training-and-testing-set\n",
        "t = data.Next_Tmax #here we define the output variable\n",
        "# To separate input from output we need to drop the output column from the dataframe to create an input vector\n",
        "x = data.drop('Next_Tmax', axis = 1)"
      ],
      "metadata": {
        "id": "QuiuW7Dx-vO5"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize the input data frame\n",
        "inputTrainingMean = x.mean() #mean and std. deviation of training data \n",
        "inputTrainingSd = x.std() #Standard deviation of training data \n",
        "x = (x - x.mean())/x.std() #Normalize all features in x to make them 0 mean and std dev = 1\n",
        "targetTrainingMean = t.mean() #Mean of training target data\n",
        "targetTrainingSd = t.std()  #Std deviation of training target data\n",
        "t = (t-t.mean())/t.std()  # normalize the target variable"
      ],
      "metadata": {
        "id": "BKk9DFeb-8PM"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate the input vector x into training and validation data in 80:20 ratio\n",
        "x_len = x.shape[0]  #number of rows in matrix x\n",
        "x_width = x.shape[1]  #number of columns in matrix x\n",
        "x_train = x.head(round(0.8*x_len))  #take first 80% (=4866) rows of x matrix as training data\n",
        "x_val = x.tail(x_len - round(0.8*x_len))  #take last 20% (=1216) rows of x matrix as validation data\n",
        "\n",
        "#Separate the target vector y into training and validation data in 80:20 ratio\n",
        "t_len = t.shape[0]  #number of rows in matrix y\n",
        "t_width = 1   #number of columns in matrix y\n",
        "t_train = t.head(round(0.8*t_len))  #take first 80% (=4866) rows of y matrix as training data\n",
        "t_val = t.tail(t_len - round(0.8*t_len))  #take last 20% (=1216) rows of y matrix as validation data"
      ],
      "metadata": {
        "id": "7AkYcG15b1Ui"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2 Question 3 begins : MSE+lamda*L2(w)**"
      ],
      "metadata": {
        "id": "mOphxfCTkosF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Initialization of different arrays and variables for TASK 3,4 and 5\n",
        "'''\n",
        "lamda = 10 #Assume initial lamda parameter\n",
        "maxiter = 200 # maximum number of iterations for gradient descent\n",
        "numLamdaVals = 6  #define the number of lamda values you are going to test\n",
        "lamdaArray = np.zeros(numLamdaVals)  #An array to store the different lamda values\n",
        "trainingRMSE = np.zeros(numLamdaVals)  #size of training MSE array = number of lamda values\n",
        "validationRMSE = np.zeros(numLamdaVals)  #An array to store validation MSE\n",
        "L = 0.1  #Assume learning rate "
      ],
      "metadata": {
        "id": "7qzyTvGd6RgO"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Training the model using gradient descent for each lamda\n",
        "'''\n",
        "\n",
        "for lCount in range(0,numLamdaVals):  #This for loop is to train model for each lamda value\n",
        "  w = np.ones(x_train.shape[1]+1) #Weights vector has one dimension more than the number of features in x matrix\n",
        "  L2_loss = np.zeros(maxiter)  # Define an array for storing L2 loss for each updated w vector in below for loop\n",
        "  lamdaArray[lCount] = lamda  #lamda array stores the lamda value\n",
        "  for i in range(maxiter):  # For loop to iterate through the maximum no of iterations for gradient descent\n",
        "    grad = L2_Gradient(x_train, t_train, w, lamda)  #Find the gradient vector for each iteration\n",
        "    temp_w = w -  L*grad  #All elements of w are updated in each iteration\n",
        "    w = temp_w #store the updated w\n",
        "    L2_loss[i] =  L2_Loss(x_train, t_train, w, lamda) #L2_Loss function for w in current iteration\n",
        "  trainingRMSE[lCount] = np.sqrt(MSE_Loss(x_train, t_train, w, lamda))  #for each lamda find training MSE\n",
        "  validationRMSE[lCount] = np.sqrt(MSE_Loss(x_val,t_val,w,lamda)) #for each lamda find validation MSE\n",
        "  lamda = lamda/10  # Update lamda by dividing it by a factor of 10"
      ],
      "metadata": {
        "id": "oz3QXw-g6hB1"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Finding minimum training RMSE and corresponding index in trainingRMSE array\n",
        "'''\n",
        "minTrainRMSE = min(trainingRMSE)  #Find out the minimum training MSE\n",
        "print('Min. Training RMSE =',minTrainRMSE)  #Print the minimum training MSE\n",
        "for i in range(0,numLamdaVals): #This for loop finds the array index corresponding to minimum Training MSE\n",
        "  if(trainingRMSE[i] == minTrainRMSE):  \n",
        "    minTrainMSEindex = i    \n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PoKsj8i69-l",
        "outputId": "e1e44bc8-54df-4543-c5ce-04532b70bf60"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min. Training RMSE = 0.45241765488595315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Plotting Training RMSE vs 1/lamda\n",
        "''' \n",
        "print('Training RMSE:',trainingRMSE)\n",
        "print('1/lamda Array: ',1./lamdaArray)\n",
        "plt.figure()\n",
        "plt.title('Training RMSE Vs log10(1/lamda plot)')\n",
        "plt.xlabel('log10(1/lamda)')\n",
        "plt.ylabel('Training RMSE')\n",
        "plt.plot(np.log10(1./lamdaArray),trainingRMSE,color='green', linestyle='-', linewidth = 3,marker='o', markerfacecolor='blue', markersize=6)\n",
        "#Since consecutive lamda values vary by large gaps we have plotted them on log scale on x axis\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "TOzVCMrt7MlF",
        "outputId": "6cca40b8-58be-40c3-8505-318f71054bcc"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RMSE: [2.26661241 0.58261445 0.46080682 0.45259575 0.45242167 0.45241765]\n",
            "1/lamda Array:  [1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgV9Zn28e9NA4KAIrLIKi6otAtqWiRqVDQaNBrcSDRGTWKGMYkzWcwkeSf74iSTZDJ5s5h3MBoT45BE3MWoaHDBCNq4oIAIIquIKLIpi9DP+0dVN9XN6ZU+fbrPuT/XVVef2p863X2eU0/96leKCMzMzOrqVOgAzMysfXKCMDOznJwgzMwsJycIMzPLyQnCzMxycoIwM7OcnCBKjKS/SbqitZe1nSR9UtKMQscBIGmypPNauO4jkj7T2jHVs68lkj6Yh+1+V9KfWrjuAEnzJe3R2nF1FE4QHYCkTZmhStLmzPilzdlWRJwVEX9o7WWbQ9Kp6XFskrRR0gJJn6qzTEh6Q1LnzLQu6bTITDtc0oOS1kpaJ2m2pLNz7Cc7vD9HTPdL+n6O6eMlvZ6Noy1JmpS+P1WSPplj/pfS+DZIujH7YSbpKGAUcFc6PlDS3ZJeS9/f4Tm211XSm5J65u2g2qm6SSoiVgPTgYmFi6qwnCA6gIjoWT0Ay4BzM9NuqV6uUB9iLfRaejx7AV8Crpd0aJ1l3gbOyoyflU7LugeYBuwH9Af+FdhQdz91hidzxPMH4BOSVGf6ZcAtEbG9OQfXip4HPgc8U3eGpA8BXwdOB/YHDgS+l1nkn0lir06oVcD9wIUN7O9k4LmI2LT7oReFW0jex5LkBNGBpd+QV0j6mqTXgd9L2kfSvZLWSHo7fT0ks05N2aC6FCLpZ+myr0o6q4XLHiDpsfSM4CFJv2nKqX0k7gPWAkfVmX0zcHlm/HLgj5l99gUOAK6PiG3p8EREtKS8cyewL/CBzPb3Ac6p3qeksyXNS49xpaSvNGXDkk6Q9LSk9enPEzLzGnzfIuI3EfEwsCXHpq8AboiIuRHxNvAD4JOZ+WcBj2a2tToirgOebiDcs4H7chzDQZL+Lumt9AzjFkm9M/OXSPo3SXMkvSPpBiUlmr9ljm2fzPKXSVqabu8bdfY1WtKT6RnhKkm/ltQ1V7CShqdnQxPTM6NVDf1eJH1E0tx0249IGplOvxkYBtyTnmV+NV1lFnCgpP0beM+KlhNEx7cf0IfkG+REkt/p79PxYcBm4NcNrH88sADoC/wEuCHHt+imLPu/wFMkH7LfJfnm3ShJnSR9JN3mojqz7wROltQ7/XD5AGm5JPVWus6fJJ0naUBT9plLRGwG/krthPRR4KWIeD4dvwH454joBRwB/L2x7UrqA0wFfkny3vwcmCpp33SRFr1vqcNJzjCqPQ8MkLSvpB4kyXNBM7YHSYKYmmO6gB8Bg4CRwNA03qwLgTOAQ4Bzgb8B/w70I/m7/FcASeXAb0mOdRDJsQ/JbGcHyVllX+D9JGdIn2sk7rHACOBM4GvKcT1D0iHAZOCLaUz3kSSErhFxGbXPzn8CkJ45LiIp1ZUcJ4iOrwr4TkRsjYjNEfFWRNwWEe9GxEbgWuCUBtZfGhHXR8QOkjLLQKC+D9qcy0oaBhwHfDv9Fj8DuLuRuAdJWkeSwO4AvhwRz9ZZZgtJCelj6XA3mW/SaelkLLAE+C9gVfptfETd/dQZetQT0x+AiyR1S8cvT6dVew8ol7RXRLwdEbuUfXL4MLAwIm6OiO0RMRl4CTi3he9bVk9gfWa8+nUvoPrb/cambkzSQUDniNglqUTEooiYlv6drSFJdHX/rn6VnqWsBB4HZkXEsxGxheR3fEy63EXAvRHxWERsBb5F8ndcva/ZETEzfb+WAP+TY191fS8i3omIF0i+IF2SY5mPAVPT43gP+BnQHTghx7JZG9n5fpYUJ4iOb036DwiApD0l/U96+r4BeAzoLamsnvVfr34REe+mL+u7QFnfsoOAtZlpAMsbifu1iOhNcg3il8Bp9Sz3R5IP6lrlpUwcKyLi6og4iOSs6Z06y70WEb3rDO/k2lH6Af0mcF76YTma5Bt+tQtJvmEvlfSoclzszmEQsLTOtKXAYFr2vmVtInn/qlW/3gisS1/3asb2zib51r+LtFz057S0tgH4E8k3/KzVmdebc4xX/10NInOc6e/jrcy+DlFSGn093dd/5NhXXdn3bWm6j7pq/S4ioipdb3Aj2+7FzvezpDhBdHx1u+O9BjgUOD4i9iK56AhJiSBfVgF9JO2ZmTa0KSum3yC/Bhyp3M0xH2fnWU2D1xYiYjnwG5LyT0tVJ6RPAA+kLVmqt/90RIwnuRh+J0lJqjGvkSSurGHASnbjfUvNpXbpYxSwOj2LfAd4haTc01Q5rz+k/oPkb+3I9O/qE7T8b2oVmeNMj3/fzPzfkpxljUj39e9N2Ff2fRtG8r7XVet3kZZHh5L8LmDX/6Xqhh8HU7uUVzKcIIpPL5Jva+vS+vd38r3DiFgKVALfVdJM8v0kNeimrr+NpET07RzzIt3WRzKtcYDkIrKk70k6OL2W0Rf4NDBzNw7nj8AHgX8iU15Kj+tSSXun5YkNZMoiDbgPOETSxyV1lvQxoJykxNLo+5ZO70byAdlFUjdJ1f+3fwSulFSeXjD+JnBTnX2fUmd73YDqprB7VJfT0g/p0STNOnPpRXLGsl7SYODfmnDs9ZkCnCPppPTi8/ep/VnUi+T93STpMOCzTdjmt9Kz58OBTwF/ybHMX4EPSzpdUheSL1NbgX+k81eTtATLGg0sSX9XJccJovj8gqSu+ibJB+X9bbTfS0kuKL4F/JDkH3RrM9a/ERgmaZfEkrbSmZtjnW3AcOAhkg+UF9N9fjKzzCDteh9Evc0805r3P4Ae7Ho94DJgSVr2uIrkmBsUEW+RtIS6huS9+SpwTkS8mS7S2Pv2IEnCPwGYlL4+Od32/SSNBaaTXGBdSu0vBJOAS+s0OthM8kEPybf0zenr04Ans+XKOr4HHEtynWMqcHtjx16f9Hf5eZLy3SqSpssrMot8Bfg4SansenJ/2Nf1KMnF5IeBn0XEgzn2u4DkzOdXJP8f55JclN6WLvIj4JvpdarqllCXAv+vWQdYRBR+YJDlgaS/kLQAyvsZTDFp7fdN0v8Cf42IOxtZ7jrgxbQZbIeh5Ga/V4EurX2viqT+JInnmAYSZ1FzgrBWIek4knsZXiVpangn8P4cLZMso728b5ImAvdExKq23O/uymeCMOhId95a+7YfSdlhX5JywWedHJqkXbxvETGprfdp7Z/PIMzMLCdfpDYzs5yKqsTUt2/fGD58eKHDMDPrMGbPnv1mRPTLNa+oEsTw4cOprKwsdBhmZh2GpHrv8XCJyczMcnKCMDOznJwgzMwsJycIMzPLyQnCzMxyKvkEccucyQz/yRF0+l4Zw39yBLfMmVzokMzM2oWiaubaXLfMmczEP3+DdyffAMtOYumwGUxcdyUAlx6V64FUZmalI29nEJKGSpqu5CHvcyV9Iccylyp5yPkLkv4haVRm3pJ0+nOS8nJzw7//7dokOSwZC1VdYMlY3p18A9+4/9p87M7MrEPJ5xnEduCaiHhGUi9gtqRpETEvs8yrwCkR8baks0j6rz8+M39spt/8Vrd8y3xYdlLtictOYtnm+fnapZlZh5G3M4iIWFX9UPeI2AjMp86zXyPiHxHxdjo6ExiSr3hyGdZ9JAyr8xTLYTOS6WZmJa5NLlKnfbYfA8xqYLErqf3A9AAelDQ77au+vm1PlFQpqXLNmjXNiuvacd+g+8WfhuHTodN7MHw63S/+NNeO+0aztmNmVozyfpFaUk/gNuCLEbGhnmXGkiSIbL3npIhYmT7VaZqklyLisbrrpv3YTwKoqKhoVt/l1ReiP9PlY2zp9CZs68H4Y871BWozM/J8BpE+GPw24JaIyPkMW0lHAb8DxqfP7wUgIlamP98A7iB5eHiru/SoS7ju/P8EBeyxicXrX8nHbszMOpx8tmIScAMwPyJ+Xs8yw0iepnVZRLycmd4jvbCNpB4kj2J8MV+xjj9sPJ07JSdTT618iqXr6u3c0MysZOTzDOJE4DLgtLSp6nOSzpZ0laSr0mW+TfKoxevqNGcdAMyQ9DzwFDA1Iu7PV6B9uvfhgwd+sGZ8yrwp+dqVmVmHkbdrEBExA1Ajy3wG+EyO6YuBUbuukT8Tyidw/6IkB90671auOeGatty9mVm7U/JdbVQ777DzaspMs1bOYtn6ZQWOyMyssJwgUn269+H0A06vGXeZycxKnRNExoTyCTWvb513awEjMTMrPCeIjPMOO48ylQEwc8VMlq9fXuCIzMwKxwkiY9899+X0A11mMjMDJ4hduMxkZpZwgqgjW2Z6csWTLjOZWclygqij7559GXvA2Jrx2+bfVsBozMwKxwkiB5eZzMycIHI6/7Dza8pM/1j+D1ZsWFHgiMzM2p4TRA79evTj1OGn1ozfPj9nR7RmZkXNCaIeLjOZWalzgqjH+SPPp5OSt+eJZU/w2sbXChyRmVnbcoKoR/8e/WvKTEFw2zy3ZjKz0uIE0QCXmcyslDlBNOCCkRfUlJlmLJvBqo2rChyRmVnbcYJoQP8e/Tll/1OAtMzkm+bMrIQ4QTTCZSYzK1V5SxCShkqaLmmepLmSvpBjGUn6paRFkuZIOjYz7wpJC9PhinzF2ZhsmenxpY+7zGRmJSOfZxDbgWsiohwYA3xeUnmdZc4CRqTDROC3AJL6AN8BjgdGA9+RtE8eY63XgJ4DOHn/k4GkzOSb5sysVOQtQUTEqoh4Jn29EZgPDK6z2Hjgj5GYCfSWNBD4EDAtItZGxNvANGBcvmJtjMtMZlaK2uQahKThwDHArDqzBgPZ/rRXpNPqm55r2xMlVUqqXLNmTWuFXMsFIy9ACIDHlj7G65tez8t+zMzak7wnCEk9gduAL0bEhtbefkRMioiKiKjo169fa28egP167scH9v9Asj+XmcysROQ1QUjqQpIcbomIXJ+qK4GhmfEh6bT6pheMy0xmVmry2YpJwA3A/Ij4eT2L3Q1cnrZmGgOsj4hVwAPAmZL2SS9On5lOK5gLR15Yq8y0etPqQoZjZpZ3+TyDOBG4DDhN0nPpcLakqyRdlS5zH7AYWARcD3wOICLWAj8Ank6H76fTCmZgr4GcNOwkAKqiijteuqOQ4ZiZ5V3nfG04ImZA+pW7/mUC+Hw9824EbsxDaC02oXwCjy97HEjKTFdVXNXIGmZmHZfvpG6GC8t3lpkeWfIIb7zzRoEjMjPLHyeIZhjUaxAnDjsRSMtM811mMrPi5QTRTG7NZGalwgmimS4ceWHN6+lLprPmnfzcnGdmVmhOEM00eK/BnDg0U2ZyayYzK1JOEC3gMpOZlQIniBa4sDxTZnp1Om+++2YBozEzyw8niBYYstcQThh6AgA7YodbM5lZUXKCaKGLRl5U89plJjMrRk4QLXRR+c4E8fdX/+4yk5kVHSeIFhq691DGDBkDJGWmO1+6s8ARmZm1LieI3ZBtzTRl3pQCRmJm1vqcIHZDtsz08KsPs3ZzQTucNTNrVU4Qu2HY3sM4fvDxAGyv2u4yk5kVFSeI3eSb5sysWDlB7KZsmemhxQ+5zGRmRcMJYjft33t/Rg8eDSRlprteuqvAEZmZtQ4niFbgMpOZFaO8JQhJN0p6Q9KL9cz/t8yzql+UtENSn3TeEkkvpPMq8xVja6lbZnp789sFjMbMrHXk8wziJmBcfTMj4qcRcXREHA38H+DRiMgW8Mem8yvyGGOrGN57OMcNOg6A96re464FLjOZWceXtwQREY8BTb1iewkwOV+xtAWXmcys2BT8GoSkPUnONG7LTA7gQUmzJU0sTGTNky0zTXtlGuu2rCtgNGZmu6/gCQI4F3iiTnnppIg4FjgL+Lykk+tbWdJESZWSKtesKdzjPw/Y5wDeN/B9QFpmcmsmM+vg2kOCuJg65aWIWJn+fAO4Axhd38oRMSkiKiKiol+/fnkNtDEuM5lZMSlogpC0N3AKcFdmWg9JvapfA2cCOVtCtTcTDt+ZIB585UHWb1lfwGjMzHZPPpu5TgaeBA6VtELSlZKuknRVZrHzgQcj4p3MtAHADEnPA08BUyPi/nzF2ZoO3OdAjh14LJCUme5ecHeBIzIza7nO+dpwRFzShGVuImkOm522GBiVn6jyb0L5BJ5Z9QyQlJkuG3VZgSMyM2uZ9nANoqhkr0M88MoDLjOZWYflBNHKDupzEMfsdwwA23Zs456X7ylwRGZmLeMEkQduzWRmxaDeBCFprwbmDctPOMUh25rpgUUPsGHrhgJGY2bWMg2dQTxS/ULSw3Xm+dFpDTi4z8Ecvd/RAGzdsZV7FrjMZGYdT0MJQpnXfRqYZzm4zGRmHV1DCSLqeZ1r3OrIJoj7F93vMpOZdTgN3QfRX9KXSc4Wql+Tjhe2T4sOYMS+Ixg1YBTPr36erTu2cu/L9/LxIz9e6LDMzJqsoTOI64FeQM/M6+rx3+U/tI4v28Ory0xm1tHUewYREd9ry0CK0YTyCXxr+rcA+NvCv7Fx60Z67dGrwFGZmTVNQ81c/0nSiPS10keIrpc0R9IxbRdix3Vo30M5sv+RADVlJjOzjqKhEtMXgCXp60tI+kc6EPgy8Mv8hlU8sherp8yfUsBIzMyap6EEsT0i3ktfnwP8MSLeioiHgB75D604ZG+au2/hfWzatqmA0ZiZNV1DCaJK0kBJ3YDTgYcy87rnN6zicVjfwzii/xEAbNm+hakvTy1wRGZmTdNQgvg2UElSZro7IuYCSDoFWJz/0IqHb5ozs46o3gQREfcC+wMjI+KfMrMqgY/lO7Bikk0Q9y28j3e2vdPA0mZm7UO9zVwlXZB5nWuR2/MRUDEa2W8kh/c7nLlr5rJ5+2amLpzKRw//aKHDMjNrUEN3Uk8BnksHqN3/UuAE0SwTyicw99G5QFJmcoIws/auoWsQFwAvA0cBrwLXRsSn0uHTbRJdEcm2Zpr68lSXmcys3WvoGsSdEXExcArwCvBfkmakF6kbld5Y94akF+uZf2p6491z6fDtzLxxkhZIWiTp6808pnapvF855f3KAdi8fTP3LbyvwBGZmTWsKU+U2wKsBzaQ9MPUrYnbvgkY18gyj0fE0enwfQBJZcBvgLOAcuASSeVN3Ge75tZMZtaRNNTVxmmSJgGzgbHA/00/yB9oyoYj4jFgbQtiGg0siojFEbEN+DMwvgXbaXeyCWLqwqm8+967BYzGzKxhDZ1BPETyYT0D2AO4XNIvq4dW2v/7JT0v6W+SDk+nDQaWZ5ZZkU7LSdJESZWSKtesWdNKYeVHeb9yDut7GADvvveuy0xm1q41lCA+Bfw38DTJvQ+z6wy76xlg/4gYBfyKFj7GNCImRURFRFT069e+H1MhyWUmM+swGuru+w/1zZM0bHd3HBEbMq/vk3SdpL7ASmBoZtEh6bSiMKF8Aj947AcA3Pvyvbz73rvs2WXPAkdlZrarBi9SS3q/pIsk9U/Hj5L0v8ATu7tjSfspvQNP0ug0lrdIzlhGSDpAUlfgYuDu3d1fe3FE/yM4dN9DgaTMdP+i+wsckZlZbg1dpP4pcCNwITBV0g+BB4FZwIjGNixpMvAkcKikFZKulHSVpKvSRS4CXpT0PEn34RdHYjtwNfAAMB/4a3U/UMXAZSYz6ygUEblnSPOAYyNii6R9SC4cHxERS9owvmapqKiIysrKQofRqDmr5zDq/40CoEeXHqz5tzV07+IOcs2s7UmaHREVueY1VGLaEhFbACLibWBhe04OHcmR/Y/kkH0PAeCd995xmcnM2qWGEsSBku6uHoAD6oxbC7nMZGYdQUOd9dW9Oe2/8hlIqZlQPoFrH78WgHtevofN7212mcnM2pWGmrk+2paBlJqjBhzFiD4jWLh2IZu2beKBVx7gvMPOK3RYZmY1mtIXk+WBy0xm1t45QRRQtgvwexbcw5btWwoYjZlZbU4QBTRqwCgO7nMwABu3beSBRU3qB9HMrE00miAk3ZNtvZQON0v6gqSmdv1tObjMZGbtWVPOIBYDm4Dr02EDsBE4JB233XBR+UU1r+9ecLfLTGbWbjQlQZwQER+PiHvS4RPAcRHxeeDYPMdX9I7Z7xgO3OdAICkzPfjKgwWOyMws0ZQE0TPbe2v6umc6ui0vUZUQl5nMrL1qSoK4BpghabqkR4DHga9I6gHU2yW4NV02Qdy94G62bt9awGjMzBKNJoiIuI+k99YvAl8ADo2IqRHxTkT8It8BloJjBx7LAb0PAGDD1g1MWzytwBGZmTW9mev7gMOBUcBHJV2ev5BKj8tMZtYeNaWZ683Az4CTgOPSIWfXsNZy2Zvm7nrpLpeZzKzgGuqsr1oFUB71PTjCWsX7Br6P4b2Hs2TdEtZvXc9Dix/iw4d8uNBhmVkJa0qJ6UVgv3wHUupcZjKz9qYpCaIvME/SA34eRH5lE8RdC+5i2w63IjazwmlKiem7LdmwpBuBc4A3IuKIHPMvBb4GiOTO7M9GxPPpvCXptB3A9voeh1dsKgZV1JSZ1m1Zx0OLH+LsEWcXOiwzK1FNaeb6aK6hCdu+CRjXwPxXgVMi4kjgB8CkOvPHRsTRpZIcICkzXTRyZ9cbLjOZWSHVmyAkzUh/bpS0ITNslLShsQ1HxGPA2gbm/yN91jXATGBIM2MvStnWTHe+dKfLTGZWMPUmiIg4Kf3ZKyL2ygy9ImKvVo7jSuBv2d0DD0qaLWliQytKmiipUlLlmjVrWjmstnfcoOMYtnfSs8m6Let4ePHDBY7IzEpVk26Uk1QmaZCkYdVDawUgaSxJgvhaZvJJEXEscBbweUkn17d+REyKiIqIqOjXr19rhVUwLjOZWXvRlBvl/gVYDUwDpqbDva2xc0lHAb8DxkfEW9XTI2Jl+vMN4A5gdGvsr6OoW2Z6b8d7BYzGzEpVU84gqvtfOjwijkyHo3Z3x+lZyO3AZRHxcmZ6D0m9ql8DZ5Lci1Eyjh98PEP3GgrA21ve5uFXXWYys7bXlASxHFjf3A1Lmgw8CRwqaYWkKyVdJemqdJFvA/sC10l6TlJlOn0ASe+xzwNPAVMj4v7m7r8jk1TrQUJT5k0pYDRmVqrUWA8akm4ADiUpLdV0EBQRP89vaM1XUVERlZWVjS/YATy5/ElOuPEEAPp078Pr17xOl7IuBY7KzIqNpNn13U7QlDOIZSTXH7oCvTKD5dHxQ45nyF5Jy9+1m9cyfcn0AkdkZqWm0TupI+J7bRGI1dZJnbho5EX8YlbyyI1b597KmQedWeCozKyUNHSj3C/Sn/dk+2ByX0xtJ9ua6Y6X7nBrJjNrUw2dQdyc/vxZWwRiuxozZAyDew1m5caVvLX5LR5Z8ghnHHRGocMysxLR0J3Us9OfLe2LyXZTJ3Wq1ZrJN82ZWVtqyo1yIyRNkTRP0uLqoS2Cs9pdgN/x0h1sr9pewGjMrJQ0pRXT74HfAtuBscAfgT/lMyjb6f1D38/gXoMBePPdN3lkySOFDcjMSkZTEkT3iHiY5J6JpRHxXcDPwmwjndSJC0deWDN+61yXmcysbTQlQWyV1AlYKOlqSecDPfMcl2VkWzPd/tLtLjOZWZtoal9MewL/CrwP+ARwRT6DstpOGHoCA3sOBJIy06NL3EbAzPKvwQQhqQz4WERsiogVEfGpiLgwIma2UXxGjjKTWzOZWRto6Ea5zhGxAzipDeOxetQqM813mcnM8q+hM4in0p/PpndPXybpguqhLYKznU4ceiL79dwPgDXvruHxpY8XOCIzK3ZNuQbRDXgLOA04Bzg3/WltqKxTmctMZtamGkoQ/SV9meRhPS+kP+emP0vqAT7tRfamudvn386Oqh0FjMbMil1DCaKMpDlrT5LuvXvWGayNnTTsJAb0GADA6ndW8/gyl5nMLH8a6qxvVUR8v80isUZVl5muq7wOSG6aO3X4qYUNysyKVkNnEGqzKKzJsq2Zbpt/m8tMZpY3DSWI03d345JulPSGpJzXLJT4paRFkuZIOjYz7wpJC9PBN+alPjDsA7XKTDOWzShwRGZWrBrq7nttK2z/JmBcA/PPAkakw0SSTgGR1Af4DnA8MBr4jqR9WiGeDq+sUxkXjNzZytitmcwsX5rSzLXFIuIxoKFEMx74YyRmAr0lDQQ+BEyLiLUR8TbJM7EbSjQlJduayWUmM8uXvCaIJhgMLM+Mr0in1Td9F5ImSqqUVLlmzZq8BdqenLz/yfTv0R+A1ze9zhPLnyhwRGZWjAqdIHZbREyKiIqIqOjXr1+hw2kTZZ3KuOCwTJnJXYCbWR4UOkGsBIZmxoek0+qbbqnso0hvm38bVVFVwGjMrBgVOkHcDVyetmYaA6yPiFXAA8CZkvZJL06fmU6z1CnDT6Hvnn0BWLVpFU8sc5nJzFpXXhOEpMnAk8ChklZIulLSVZKuShe5D1gMLAKuBz4HNS2ofgA8nQ7fb6VWVUWjc6fOtcpMU+ZNKWA0ZlaMFBGFjqHVVFRURGVlZaHDaDMPLX6IM24+A4BBvQax/EvL6aRCnxSaWUciaXZEVOSa50+TDuzU4afWlJle2/gaTy5/ssARmVkxcYLowDp36sz5h51fM+6b5sysNTlBdHDZm+amzJvi1kxm1mqcIDq4sQeMZd/u+wKwcuNKZq7w48LNrHU4QXRwu5SZfNOcmbUSJ4gikO0CfMp8l5nMrHU4QRSBscPH0qd7HwBWbFjBrBWzChyRmRUDJ4gi0KWsi1szmVmrc4IoEm7NZGatzQmiSJx2wGns0y15ptLyDct5auVTBY7IzDo6J4gi0aWsC+cddl7NuFszmdnucoIoIrXKTPOnUEz9bJlZ23OCKCKnH3g6vbv1BmDZ+mU8/drTBY7IzDoyJ4gi0rWsq8tMZtZqnCCKTLbMdOu8W11mMrMWc4IoMh888IM1Zaal65dS+VrpPB/DzFqXE0SR6VrWlfGHjq8Z901zZtZSThBFyGUmM2sN+X4m9ThJCyQtkvT1HPP/W9Jz6fCypHWZeTsy8+7OZ5zF5oyDzmDvPfYGYMm6JcxeNbvAEZlZR5S3BCGpDDmIB1YAAA7cSURBVPgNcBZQDlwiqTy7TER8KSKOjoijgV8Bt2dmb66eFxEfyVecxahrWVfGH5YpM7k1k5m1QD7PIEYDiyJicURsA/4MjG9g+UuAyXmMp6S4zGRmuyufCWIwsDwzviKdtgtJ+wMHAH/PTO4mqVLSTEnn5VovXXdiulzlmjVrWiPuonDGgWew1x57AfDquld5ZtUzBY7IzDqa9nKR+mJgSkTsyEzbPyIqgI8Dv5B0UK4VI2JSRFREREW/fv3aItYOYY/Oe7g1k5ntlnwmiJXA0Mz4kHRaLhdTp7wUESvTn4uBR4BjWj/E4nZR+UU1r11mMrPmymeCeBoYIekASV1JksAurZEkHQbsAzyZmbaPpD3S132BE4F5eYy1KJ150Jn06toLgMVvL+bZ158tcERm1pHkLUFExHbgauABYD7w14iYK+n7krKtki4G/hy1v96OBColPQ9MB34cEU4QzdStczc+cujOt9qtmcysOVRMZYeKioqorHTXEll3vXQX5/0lucZ/cJ+Defnql5FU4KjMrL2QNDu93ruL9nKR2vLkQwd/qKbMtGjtIp5f/XyBIzKzjsIJosh169yNcw89t2bcZSYzayoniBLgm+bMrCWcIErAhw76ED279gRg4dqFzFk9p8ARmVlH4ARRArp36c65h2TKTL5pzsyawAmiRLjMZGbN5QRRIsYdPK6mzPTyWy/zwhsvFDgiM2vvnCBKRPcu3TnnkHNqxt2aycwa4wRRQlxmMrPmcIIoIWcdfBY9uvQAYMFbC3jxjRcLHJGZtWdOECWke5fufPiQD0MVsLUnR/32aIb/5AhumePnNJnZrjoXOgBrW/v1GAjvDoApk2HZSSwdNoPPvP0pqmIHl436RKHDM7N2xAmixNwxZ1qSHJaMTSYsGcuWP/+eKzqN53fPXs+YwWMYM2QMxw85nkG9BhU2WDMrKCeIErNiy0uw7KTaE5edRHTZxGNLH+OxpY/VTB6611DGDBlTMxyz3zF079K9jSM2s0Jxgigxw7qPZOmwGTvPIACGzYBtPWCPTbWWXb5hOcvnLa+587pzp84cvd/RNWcZY4aM4cB9DnT34WZFys+DKDG3zJnMxD9/g3cn35CcSQybwZ6XXMl/jv8Kg/cayMwVM5m5ciZPr3yazds3N7q9vnv25fjBx9ckjOMGHcfe3fZugyMxs9bQ0PMgnCBK0C1zJvON+69l2eb5DOs+kmvHfYNLj7qk1jLbq7bzwuoXmLVyVpI0VsxkwVsLGt22EOX9ypPrGGniKO9XTlmnsnwdjpntBicIaxVrN6/lqZVPMXPFzJrEsW7LukbX69m1J6MHj2bM4OTi95ghY+jfo38bRGxmjXGCsLyoiioWvrWw5gxj5sqZvLD6BXbEjkbXPaD3AbUugI8aMIo9Ou/RBlGbWVbBEoSkccD/BcqA30XEj+vM/yTwU2BlOunXEfG7dN4VwDfT6T+MiD80tj8niMJ7Z9s7zF41e2fSWDGTVZtWNbpe17KuHDvw2FoXwIftPcwXwM3yrCAJQlIZ8DJwBrACeBq4JCLmZZb5JFAREVfXWbcPUAlUAAHMBt4XEW83tE8niPYnIlixYUWts4zZr81m646tja47oMeAWmcZFYMqanqkNbPW0VCCyGcz19HAoohYnAbxZ2A8MK/BtRIfAqZFxNp03WnAOMB9QnQwkhi691CG7j2UCYcnnQVu27GN519/vtYF8FfefmWXdVe/s5q7FtzFXQvuAqCTOnFE/yNqnWUc2vdQOsk9xpjlQz4TxGBgeWZ8BXB8juUulHQyydnGlyJieT3rDs61E0kTgYkAw4YNa4WwLd+6lnXluMHHcdzg47h6dHLyuOadNTUJY9bKWcxaMYuN2zbWWq8qqpizeg5zVs9h0jOTANh7j72TC+Bpwjh+8PHsu+e+bX5MZsWo0DfK3QNMjoitkv4Z+ANwWnM2EBGTgEmQlJhaP0RrC/169OOcQ86peWbFjqodvPTmSzVnGLNWzuLFN14kqP0rXr91PdMWT2Pa4mk100b0GVGrme1RA47ir3OnNNq018xqy2eCWAkMzYwPYefFaAAi4q3M6O+An2TWPbXOuo+0eoTWbpV1KuPw/odzeP/DufLYKwHYsHUDla9V1roAvubdNbusu3DtQhauXcjNc24GoLO6ULWpL1W33lLTQeGn3rqcvy28j9FDjqNzp861hjKV1R7vVNbg/OYuU6ayvF98b8q9LsXGx9z6x5zPi9SdScpGp5N84D8NfDwi5maWGRgRq9LX5wNfi4gx6UXq2cCx6aLPkFykXtvQPn2RurREBEvWLal1AfzZVc/yXtV7tRfc2hMm3127e5Hh0+GSj+zSvUhbKVNZqyee6mH5uhU8tXApO/56c83d8p0/ehkfGHkoB+97ULPiFC1PZLubBJuz74VvLuLR+fPZXueYTykv55C+B+9WHO3Vy28u4tF582od856XXMmki69tVpIoZDPXs4FfkDRzvTEirpX0faAyIu6W9CPgI8B2YC3w2Yh4KV3308C/p5u6NiJ+39j+nCBsy/YtPLvq2VoXwJeuWwY/2ApVXXYu2Ok9+NYeoCKsSrbDhJh3PubE8Ons/9l/YclXm/4wMN8oZyVtyI9HsvJ/rtvlH6nXJz/BFcddwPaq7ckQ29lRtWPneNV2dkTt8e1VjS/T2PyqqMrvAYdKKyGCj7lap/fQt7tR9Z3Gb1atVqhmrmbtwn+e/W0mbrhylw4Kf3v+zwpSo46IZieV5sz//J1f560cPfb2KRvGj87+9/oDyxFni4+R3ftQbu6+v3n/j1mb45j3KRvKD8d9bbdiaa++ef9/8naOYx7WfWSr7cMJwopedRL4Ru9/yVzMa16dtjVJorOS6wX5sL2qionv7poQfzn+R0V70XavPXozcfOux/yr8T8u2mPee499ch7zteOubbV9OEFYSbj0qEuK9oOirvaWENuCjzk/x+xrEGZmJayhaxDuo8DMzHJygjAzs5ycIMzMLCcnCDMzy8kJwszMciqqVkyS1gBLW7h6X+DNVgynI/AxF79SO17wMTfX/hHRL9eMokoQu0NSZX1NvYqVj7n4ldrxgo+5NbnEZGZmOTlBmJlZTk4QO00qdAAF4GMufqV2vOBjbjW+BmFmZjn5DMLMzHJygjAzs5ycIDIkTZA0V1KVpKJtJidpnKQFkhZJ+nqh48k3STdKekNS05/D2MFJGippuqR56d/0FwodU75J6ibpKUnPp8f8vULH1BYklUl6VtK9rb1tJ4jaXgQuAB4rdCD5IqkM+A1wFlAOXCKpvLBR5d1NwLhCB9HGtgPXREQ5MAb4fAn8nrcCp0XEKOBoYJykMQWOqS18AZifjw07QWRExPyIWFDoOPJsNLAoIhZHxDbgz8D4AseUVxHxGLC20HG0pYhYFRHPpK83knyADC5sVPkViU3paJd0KOpWOJKGAB8GfpeP7TtBlJ7BwPLM+AqK/IOj1EkaDhwDzCpsJPmXllueA94ApkVEsR/zL4CvAlX52HjJJQhJD0l6McdQ1N+irTRJ6gncBnwxIjYUOp58i4gdEXE0MAQYLemIQseUL5LOAd6IiNn52kfJPZM6Ij5Y6BgKbCUwNDM+JJ1mRUZSF5LkcEtE3F7oeNpSRKyTNJ3k2lOxNk44EfiIpLOBbsBekv4UEZ9orR2U3BmE8TQwQtIBkroCFwN3Fzgma2WSBNwAzI+Inxc6nrYgqZ+k3unr7sAZwEuFjSp/IuL/RMSQiBhO8n/899ZMDuAEUYuk8yWtAN4PTJX0QKFjam0RsR24GniA5MLlXyNibmGjyi9Jk4EngUMlrZB0ZaFjagMnApcBp0l6Lh3OLnRQeTYQmC5pDskXoWkR0epNP0uJu9owM7OcfAZhZmY5OUGYmVlOThBmZpaTE4SZmeXkBGFmZjk5QVjRkbSp8aXqXffqtJfbkNQ3M12SfpnOmyPp2My8gdU9aUraN+1FdZOkX+fY/tclXSrpu5K+0tI4G4j/k7n2W2eZcyR9v7X3bcXHCcKstieADwJL60w/CxiRDhOB32bmfRm4Pn29BfgWUN+H/4eAB1sr2BaaCpwrac8Cx2HtnBOEFa30W/9P0762XpD0sXR6J0nXSXpJ0jRJ90m6CCAino2IJTk2Nx74Y9pj6Eygt6SB6bwLgfvT9d+JiBkkiaJuPHsBXSNiTZ3p/yTp6fQ5BrdVf3BLuknSbyXNlLRY0qnpsy3mS7ops/6nJL0s6SmSG+Sqp58raVb6rICHJA1IYwzgEeCcFrytVkKcIKyYXUDyXIBRJGcFP00/1C8AhpM8D+MykjvnG5OzF1xJBwBvR8TWJmzjg8DDOabfHhHHpc8xmA9k7/TeJ43vSyRdovw3cDhwpKSj0+P5HkliOCk9pmozgDERcQxJt+5fzcyrBD7QhJithJVcZ31WUk4CJkfEDmC1pEeB49Lpt0ZEFfB62qlbSw0E1jS6VGIc8Psc04+Q9EOgN9CTpBuUavdEREh6AVgdES8ASJpLkuSGA49Un5VI+gtwSLruEOAvaRLpCrya2e4bwKAmxm0lymcQZk1TXy+4m0l60myK0cBTOabfBFwdEUeSnA1kt1d9ZlKVeV093tgXvF8Bv063+891ttstjd2sXk4QVsweBz6WPkSmH3AyyQf0E8CF6bWIAcCpTdjW3cDl6XWNMcD6iFgFvEzyLb5Bkg4HXkrPZurqBaxKu+e+tAmxZM0CTklbT3UBJmTm7c3OrtyvqLPeIRRvN9jWSpwgrJjdAcwBngf+Dnw1Il4neUbCCmAe8CfgGWA9gKR/TXv0HQLMkVT9KMf7gMXAIpIWS5+D5KI08Iqkg6t3KmkJ8HPgk2nvseUkraDuryfOb5F80D9BM7unTpPUd0l6q32C2s8m/i5wq6TZwJt1Vh1L0prJrF7uzdVKkqSeEbFJ0r4kZxUnpsmjJds6H3hfRHyzgWWmAZenH+gFlZ41/W9EnF7oWKx980VqK1X3pg+X6Qr8oKXJASAi7kgTTUPLnNHS7efBMOCaQgdh7Z/PIMzMLCdfgzAzs5ycIMzMLCcnCDMzy8kJwszMcnKCMDOznP4/DVXSsR9zARoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Finding minimum validation MSE and corresponding index in validationMSE array\n",
        "'''\n",
        "minValidationRMSE = min(validationRMSE)   #Find out the minimum validation MSE\n",
        "for i in range(0,numLamdaVals): \n",
        "  if(validationRMSE[i] == minValidationRMSE):\n",
        "    minValidationMSEindex = i    \n",
        "    break\n",
        "optimumLamda = lamdaArray[minValidationMSEindex] #Optimum Lamda corresponds to lamda value at mimimum Validation MSE Index"
      ],
      "metadata": {
        "id": "YgcdqS4p7z01"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Plotting Validation MSE vs 1/lamda\n",
        "'''\n",
        "print('Valdation RMSE:',validationRMSE)\n",
        "print('1/lamda Array: ',1./lamdaArray)\n",
        "print('Best lamda which gives min. Validation RMSE = ',optimumLamda)\n",
        "print('Validation RMSE for best lamda = ',validationRMSE[minValidationMSEindex]) # Validation MSE corresponding to best lamda\n",
        "print('Validation NRMSE for best lamda = ',validationRMSE[minValidationMSEindex]/np.std(t_val))  # Validation NMSE corresponding to best lamda\n",
        "plt.figure()\n",
        "plt.xlabel('log10(1/lamda)')\n",
        "plt.ylabel('Validation RMSE')\n",
        "#Since consecutive lamda values vary by large gaps we have plotted them on log scale on x axis\n",
        "plt.plot(np.log10(1./lamdaArray),validationRMSE,color='red', linestyle='-', linewidth = 3,marker='o', markerfacecolor='red', markersize=6)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "sQLQlxMN78j8",
        "outputId": "4233bcf8-dbfc-4727-b1cd-e79fbd8a447b"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valdation RMSE: [2.59571827 0.72630327 0.46646787 0.47700122 0.47948328 0.47974907]\n",
            "1/lamda Array:  [1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04]\n",
            "Best lamda which gives min. Validation RMSE =  0.1\n",
            "Validation RMSE for best lamda =  0.4664678674231005\n",
            "Validation NRMSE for best lamda =  0.377994227709594\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Using optimum lamda we will run gradient descent on training data and find the best w vector\n",
        "'''\n",
        "w = np.ones(x_train.shape[1]+1) #Weights vector has one dimension more than the number of features in x matrix\n",
        "for i in range(maxiter): #This for loop finds the array index corresponding to minimum Validation MSE\n",
        "  grad = L2_Gradient(x_train, t_train, w, optimumLamda) #\n",
        "  temp_w = w -  L*grad\n",
        "  w = temp_w  \n",
        "  L2_loss[i] =  L2_Loss(x_train, t_train, w, optimumLamda) #L2_Loss function\n",
        "print('Best weight vector for optimum lamda = ',w)\n",
        "wTest = w #This w will be used for testing the model in Question 6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiwYLPonC144",
        "outputId": "27788c38-bef4-4a4a-82ed-7de4678871da"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weight vector for optimum lamda =  [ 1.23749963e-01  4.27260595e-02  3.90310926e-02 -3.04588077e-02\n",
            "  4.40957959e-01  1.52473587e-01 -1.08650241e-01  8.37903975e-02\n",
            " -1.24124148e-01 -6.38478641e-02 -7.46160812e-02 -8.86831090e-02\n",
            " -2.70784135e-02  7.09598337e-02  1.21154155e-03  2.45364430e-04\n",
            " -1.78292387e-02 -2.45968336e-02 -5.97766455e-02  6.84466742e-02\n",
            "  4.22290140e-02 -5.05792878e-03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations for Part 2 Question 3:**\n",
        "\n",
        "1) For** Learning Rate L = 1**:\n",
        "\n",
        "Training RMSE: [inf inf inf inf inf inf]\n",
        "\n",
        "1/lamda Array:  [1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04]\n",
        "\n",
        "Valdation RMSE: [inf inf inf inf inf inf]\n",
        "\n",
        "Clearly learning rate of 1 is not an optimum choice\n",
        "\n",
        "2)For **Learning Rate L = 0.1**:\n",
        "\n",
        "Training RMSE: [2.26661241 0.58261445 0.46080682 0.45259575 0.45242167 0.45241765]\n",
        "\n",
        "1/lamda Array: [1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04]\n",
        "\n",
        "Valdation RMSE: [2.59571827 0.72630327 0.46646787 0.47700122 0.47948328 0.47974907](Min. validation MSE occurs at: **lamda = 0.1**)\n",
        "\n",
        "3)For **Learning Rate L = 0.01**: \n",
        "\n",
        "Training RMSE: [0.88159037 0.5795732  0.46292016 0.4647183  0.46509646 0.46513624]\n",
        "\n",
        "1/lamda Array: [1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04] \n",
        "\n",
        "Valdation RMSE: [1.21536351 0.71500768 0.45982222 0.46406411 0.46480869 0.46488615] (Min. validation MSE occurs at: **lamda = 0.1**)\n",
        "\n",
        "Therefore, the minimum validation RMSE occurs at lamda = 0.1. Learning Rate of 0.1 and 0.01 have approximately same validation RMSE for lamda = 0.1. Since Learning rate of 0.1 needs lesser number of iterations to converge, learning rate of 0.1 will be optimum.\n",
        "\n"
      ],
      "metadata": {
        "id": "rzKBMM6mT4qQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2 Question 4 Starts:  MSE+lamda*L1(w)**"
      ],
      "metadata": {
        "id": "TOimIKUUZNGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Initialization of different arrays and variables for TASK 3,4 and 5\n",
        "'''\n",
        "lamda = 10 #Assume initial lamda parameter\n",
        "maxiter = 200 # maximum number of iterations for gradient descent\n",
        "numLamdaVals = 6  #define the number of lamda values you are going to test\n",
        "lamdaArray = np.zeros(numLamdaVals)  #An array to store the different lamda values\n",
        "trainingRMSE = np.zeros(numLamdaVals)  #size of training MSE array = number of lamda values\n",
        "validationRMSE = np.zeros(numLamdaVals)  #An array to store validation MSE\n",
        "L = 0.1  #Assume learning rate "
      ],
      "metadata": {
        "id": "i2AaRSmmDLuL"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Training the model using gradient descent for each lamda\n",
        "'''\n",
        "for lCount in range(0,numLamdaVals):  #This for loop is to train model for each lamda value\n",
        "  w = np.ones(x_train.shape[1]+1) #Weights vector has one dimension more than the number of features in x matrix\n",
        "  L1_loss = np.zeros(maxiter)  # Define an array for storing L2 loss for each updated w vector in below for loop\n",
        "  lamdaArray[lCount] = lamda  #lamda array stores the lamda value\n",
        "  for i in range(maxiter):  # For loop to iterate through the maximum no of iterations for gradient descent\n",
        "    grad = L1_Gradient(x_train, t_train, w, lamda)  #Find the gradient vector for each iteration\n",
        "    temp_w = w -  L*grad  #All elements of w are updated in each iteration\n",
        "    w= temp_w #store the updated w\n",
        "    L1_loss[i] =  L1_Loss(x_train, t_train, w, lamda) #L2_Loss function for w in current iteration\n",
        "  trainingRMSE[lCount] = np.sqrt(MSE_Loss(x_train, t_train, w, lamda))  #for each lamda find training MSE\n",
        "  validationRMSE[lCount] = np.sqrt(MSE_Loss(x_val,t_val,w,lamda)) #for each lamda find validation MSE\n",
        "  lamda = lamda/10  # Update lamda by dividing it by a factor of 10"
      ],
      "metadata": {
        "id": "L9iTsXkBYzVE"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Finding minimum training RMSE and corresponding index in trainingRMSE array\n",
        "'''\n",
        "minTrainRMSE = min(trainingRMSE)  #Find out the minimum training MSE\n",
        "print('Min. Training RMSE =',minTrainRMSE)  #Print the minimum training MSE\n",
        "for i in range(0,numLamdaVals): #This for loop finds the array index corresponding to minimum Training MSE\n",
        "  if(trainingRMSE[i] == minTrainRMSE):\n",
        "    minTrainMSEindex = i    \n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a938b1-8947-49b2-b94c-4ad2da69a457",
        "id": "gnmXpPdpChAL"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min. Training RMSE = 0.4518543295892992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Plotting Training RMSE vs log10(1/lamda)\n",
        "''' \n",
        "print('Training RMSE:',trainingRMSE)\n",
        "print('1/lamda Array: ',1./lamdaArray)\n",
        "plt.figure()\n",
        "plt.title('Training RMSE Vs log10(1/lamda) plot')\n",
        "plt.xlabel('log10(1/lamda axis)')\n",
        "plt.ylabel('Training RMSE')\n",
        "#Since consecutive lamda values vary by large gaps we have plotted them on log scale on x axis\n",
        "plt.plot(np.log10(1./lamdaArray),trainingRMSE,color='green', linestyle='-', linewidth = 3,marker='o', markerfacecolor='blue', markersize=6)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "14c6d143-cb69-4071-d75f-e117705bcc9b",
        "id": "A414Bo6kCul5"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RMSE: [8.14217193 0.70561497 0.4854272  0.45295417 0.45186751 0.45185433]\n",
            "1/lamda Array:  [1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5wd5X33/c9Xq96FtEgCIQRYDTDNMqYomA6iSciJAWPcSJTHwbjfvpNgO5AY37kdx4/jOPETHNyx4hgj0UVvIoCRKKKoIIEkBCorobbq0v6eP2Z2Obs6e3Yl7dk55ft+vea1M3PmzPWbs7u/uc4111yjiMDMzCpPl6wDMDOz4nCCNzOrUE7wZmYVygnezKxCOcGbmVUoJ3gzswrlBF9mJN0v6dMdva29T9JnJM3OOg4ASdMlTdnP9z4u6c87OqZWyloq6dx2bNdD0gJJtcUuy5zgO4Wk+pypQdK2nOWr92VfETEpIn7Z0dvuC0lnpsdRL2mzpIWSPttim5C0RlLXnHXd0nWRs+4YSQ9Kek/SBklzJV2Up5zc6dQ8Mc2S9Pd51k+WtCo3js4k6Zb082mQ9Jk8r38ljW+TpJ9J6pHz2nHA8cCd6fJwSXdJejf9fEfl2V93SWsl9S3aQR2AiNgB/Az462KXlf79rCh2OaXMCb4TRETfxglYDlyas+62xu2ySkL76d30ePoDXwF+Kmlsi23WA5Nyliel63LdDTwEDAMOBr4IbGpZTovpmTzx/BL4pCS1WH8NcFtE7N6Xg+tALwN/BbzQ8gVJF5AkunOAw4EjgZtyNvlLktgbT4gNwCzgYwXKOwN4KSLqDzz0ovkt8Onck5kVhxN8hhprGJL+t6RVwM8lDZJ0j6Q6SevT+RE572n62t3YlCDp++m2b0matJ/bHiHpybRG/rCkf5P0m7aOIRL3Ae8Bx7V4+dfAp3KWPwX8KqfMIcARwE8jYmc6PR0R+9M8MhMYDPxJzv4HAZc0linpIkmvp8f4jqSvt2fHkk6T9LykjenP03JeK/i5RcS/RcQjwPY8u/40cGtEvBYR64F/AD6T8/ok4Imcfa2OiH8Hni8Q7kXAfXmO4ShJj0pal9bwb5M0MOf1pZL+l6R5krZIulXSUCXNfI3HNihn+2skLUv3d0OLsk6W9Ez6jWylpB9L6p5zHCtITvSn5DsASTdKul3S79KyX5B0fCvb9pD0w/RbzbvpfA9JfYD7gUNyvvkdUuBzq0hO8NkbBhxEUoObRvI7+Xm6PBLYBvy4wPs/AiwEhgDfA27NU4ttz7a/Bf5IkiRvJKn5tklSF0mXpftc3OLlmcAZkgamyeFPSJsbUuvS9/xG0hRJQ9tTZj4RsQ34b5qfUD4OLIiIl9PlW4G/jIh+wLHAo23tV9JBwL3Aj0g+mx8A90oanG6yX59b6hiSGn6jl4GhkganCeoIkt/XvrgojbclAf8HOAQYDxyWxpvrY8B5wBjgUpIE+bdALcnf5RcBJB0N/ITkWA8hOfYROfvZQ/KtbghwKsk3lL9qUdZ8kuan1kwGfk/yv/FbYKakbnm2u4HkRHFCur+TgW9GxBaSE2TuN8B3C5RXkZzgs9cA/F1E7IiIbRGxLiL+EBFbI2IzcDPw0QLvXxYRP42IPSTNFMOB1hJl3m0ljQQ+DHw7rUXPBu5qI+5DJG0gOQHNAL4aES+22GY7SRPMFel0Fzk12bTp4SxgKfDPwMq0Njy6ZTktpj6txPRL4E8l9UyXP5Wua7QLOFpS/4hYHxF7NZvkcTHwRkT8OiJ2R8R0YAFw6X5+brn6Ahtzlhvn+wGNtevN7d2ZpKOArhGx10khIhZHxEPp31kdyYmq5d/Vv6bfEt4BngKei4gXI2I7ye/4xHS7PwXuiYgn0zb1b5H8HTeWNTcink0/r6XAf+Qpa3POMeYzNyJuj4hdaaw9yV/jvxr4+4hYkx7XTezbSbaiOcFnry79BwJAUm9J/5F+/d0EPAkMlFTTyvtXNc5ExNZ0trULbK1tewjwXs46gLfbiPvdiBhI0gb/I+DsVrb7FUmibdY8kxPHioj4QkQcRfKtZUuL7d6NiIEtpi35CkoT7FpgSprsTiap/TX6GEkNd5mkJ5TnYm0ehwDLWqxbBhzK/n1uuepJPr9GjfObgQ3pfL992N9FJLXuvaTNLf+VNk1tAn5DUsPOtTpnflue5ca/q0PIOc7097Eup6wxSpoWV6VlfTdPWf14/xjzyd1/A7AiLbellr+fZa1sV5Wc4LPXcjjPrwFjgY9ERH+Si2aQfMUulpXAQZJ656w7rD1vTGtw/xv4oPJ353uK979VFGxbj4i3gX8jaT7ZX40nlE8CD0REU5KKiOcjYjLJxdyZJE06bXmX5MSTayTwDgfwuaVeo3kzxfHA6vRb3BZgCUlzSXvlbX9PfZfkb+2D6d/VJ9n/v6mV5BxnevyDc17/Ccm3nNFpWX+bp6zxNG+eail3/11ImoDyNbG0/P2MzNmu6ofKdYIvPf1Iaksb0vbfvyt2gRGxDJgD3Kikm92pJG2w7X3/TpImlm/neS3SfV2W0xsESC6CSrpJ0gfStvwhwOeAZw/gcH4FnAv8BTnNM+lxXS1pQPq1fxM5zQoF3AeMkfQJSV0lXQEcTdJE0ebnlq7vSZLguknqmSasxlivlXR0esHzm8AvWpT90Rb76wk09j7p0dgclSbZk4HHWjmOfiTfGDZKOhT4X+049tbcDlwiaWJ68fTvaZ5L+pF8vvWSxgGfb3EMh5K0rRf6PX9I0lQlPcu+DOxoZfvpwDcl1aZ/P98m+XYCyTeQwZIG7PMRVggn+NLzQ6AXSVPDsyTd4jrD1SQXxNYB3wF+R/JP1V4/A0ZK2uvEkPYSeS3Pe3YCo4CHSRLCq2mZn8nZJrcXROPUajfBtM33f4A+7N0efg2wNG02+H9IjrmgiFhH0hPnaySfzTeASyJibbpJW5/bgyQn7NOAW9L5M9J9zyK52P0YSffZZTQ/od8CXN3iovk2kkQNSS15Wzp/NvBMbnNfCzcBJ5G0898L3NHWsbcm/V1eR9L8tZKkR0xuf/OvA58gaWr6KclnkusTwC/Tb3+tuZPkus16kt/b1PTE3NJ3SE6y84BXSLqjfieNcwHJCeDN9NpN1TXdKPzAD8tD0u9IeqAU/RtEJenoz03Sb4H/joiZbWz378CraTfKkqWk7/vLwBkRsaaVbW4EPhARn+zM2CpROd1YY0Uk6cMkfdnfAs4n6ab2j5kGVQaK/blFxCfauelLJD2WSlpaax+XdRzVwgneGg0j+do+mOTr9ufzdHu0vZXE5xYRt3R2mVb63ERjZlahfJHVzKxClVQTzZAhQ2LUqFFZh2FmVjbmzp27NiLyDr9cUgl+1KhRzJkzJ+swzMzKhqSWd1o3cRONmVmFcoI3M6tQTvBmZhXKCd7MrEI5wZuZVaiyT/C3zZvOqO8dS5ebahj1vWO5bd70rEMyMysJJdVNcl/dNm860/7rBrZOvxWWT2TZyNlM23AtAFcfd1XG0ZmZZausa/B/e//NSXJfehY0dIOlZ7F1+q3cMOvmrEMzM8tcWSf4t7fPh+UTm69cPpHl2+ZnE5CZWQkpaoKX9BVJr0l6VdL0nIchd4iRvcbDyBZPgRs5O1lvZlblipbg08dyfRGYEBHHAjXAlR1Zxs0X3kCvKz8Hox6DLrtg1GP0uvJz3HzhDR1ZjJlZWSr2RdauQC9Ju4De5H9o7n5rvJB6bbePs6PLOtjZhytPvsIXWM3MKGINPiLeAb5P8qzJlcDGiHiw5XaSpkmaI2lOXV3dPpdz9XFX8U8XfxsU0KOed+tXtP0mM7MqUMwmmkEkjy87AjgE6CNpr2csRsQtETEhIibU1uYd8bJNU8ZNaZp/5K1H2LB9w/4FbWZWQYp5kfVc4K2IqEufhn4HyZPlO9xhAw7jw4d8GIDdDbu5d9G9xSjGzKysFDPBLwdOkdRbkoBzgKL1X7x83OVN83csuKNYxZiZlY1itsE/B9wOvAC8kpZVtAcDTx0/tWl+1uJZbN21tVhFmZmVhaL2g4+Iv4uIcRFxbERcExE7ilXW2CFjGT8k6f++dddWHlyy1/VcM7OqUtZ3sraUW4u/Y76bacysulVUgs9th7970d3s2rMrw2jMzLJVUQn+pOEnMXLASAA2bN/A40sfzzYgM7MMVVSCl9SsFj9jwYwMozEzy1ZFJXho3g4/c8FMGqIhw2jMzLJTcQn+9MNOp7Z3ckfsyvqVPLfiuYwjMjPLRsUl+JouNUweO7lp2b1pzKxaVVyCh+bNNDMWzCAiMozGzCwbFZngzz7ibPp17wfAkvVLeGXNKxlHZGbW+Soywffo2oNLxlzStDxjvnvTmFn1qcgEDx58zMysYhP8pNGT6FHTA4B5q+ex5L0lGUdkZta5KjbB9+3el/OPOr9p2Tc9mVm1qdgED3v3pjEzqyYVneAvHXMpNaoB4H/e/h9Wbl6ZcURmZp2nohP84N6D+eiojzYt37nwzgyjMTPrXMV86PZYSS/lTJskfblY5bWmWW8a39VqZlWkmI/sWxgRJ0TECcCHgK1ApzeETxk3pWn+saWPsX7b+s4OwcwsE53VRHMOsCQilnVSeU1G9B/ByYeeDMDuht3cs+iezg7BzCwTnZXgrwSmd1JZe5k6zr1pzKz6FD3BS+oOXAb8vpXXp0maI2lOXV1dUWK4fPz77fCzFs9iy84tRSnHzKyUdEYNfhLwQkSszvdiRNwSERMiYkJtbW1RAhgzeAzH1B4DwLbd23hgyQNFKcfMrJR0RoK/igybZxr5UX5mVm2KmuAl9QHOAzLvn5h7V+vdC+9m556dGUZjZlZ8RU3wEbElIgZHxMZiltMeJww7gcMHHA7Axh0beXzp49kGZGZWZBV9J2suSc1q8b7pycwqXdUkeGjeDj9zwUz2NOzJMBozs+KqqgR/2mGncXCfgwFYvWU1z654NuOIzMyKp6oSfE2XGqaMfX/oAvemMbNKVlUJHprf9HTH/DuIiAyjMTMrnqpL8GcfcTb9e/QH4K0NbzFv9byMIzIzK46qS/Dda7pzyZhLmpbdm8bMKlXVJXjw4GNmVh2qMsFf+IEL6dm1JwCvrHmFxe8tzjgiM7OOV5UJvk/3Plxw1AVNyzPmuxZvZpWnKhM8tHiU3wK3w5tZ5anaBH/p2EupUQ0Az654lnc3v5txRGZmHatqE/xBvQ7izFFnNi3PXDAzu2DMzIqgahM8NB9C2L1pzKzSVHWCnzx2ctP8Y289xnvb3sswGjOzjlXVCf7Q/odyyohTANgTe7h74d0ZR2Rm1nGqOsGDH+VnZpWr2I/sGyjpdkkLJM2XdGoxy9sfuQn+gSUPsGXnlgyjMTPrOMWuwf8LMCsixgHHA/OLXN4+Gz14NMcefCwA23dvZ9biWRlHZGbWMYqW4CUNAM4AbgWIiJ0RsaFY5R2I3LFpfNOTmVWKYtbgjwDqgJ9LelHSf0rq03IjSdMkzZE0p66urojhtC53jPh7Ft3Dzj07M4nDzKwjFTPBdwVOAn4SEScCW4C/brlRRNwSERMiYkJtbW0Rw2nd8UOP54iBRwCwaccmHn3r0UziMDPrSMVM8CuAFRHxXLp8O0nCLzmSmt/05MHHzKwCFC3BR8Qq4G1JY9NV5wCvF6u8A5Xbm2bmwpnsadiTYTRmZgeu2L1orgdukzQPOAH4bpHL22+nHnYqw/oOA2DNljU8s+KZjCMyMzswRU3wEfFS2r5+XERMiYj1xSzvQHRRl2ZDF/hRfmZW7qr+TtZcLQcfi4gMozEzOzBO8DnOHHUmA3oMAGDphqW8tOqljCMyM9t/TvA5utd059KxlzYte2waMytnTvAtNHuUn9vhzayMtZrgJfUv8NrI4oSTvQuOuoBeXXsB8FrdayxatyjjiMzM9k+hGvzjjTOSHmnxWsU+365P9z5c8IELmpZ905OZlatCCV458wcVeK3i5A4+5nZ4MytXhRJ8tDKfb7miXDLmErp26QrAc+88x4pNKzKOyMxs3xVK8AdL+qqkr+XMNy5nMypYJxnUaxBnjTqraXnmgoptkTKzClYowf8U6Af0zZlvXP7P4oeWLT/Kz8zKXdfWXoiImzozkFIzZdwUrrvvOoLgiaVPsG7rOgb3Hpx1WGZm7Vaom+RfSBqdzkvSzyRtlDRP0omdF2I2hvcbzikjTgFgT+zh7kV3ZxyRmdm+KdRE8yVgaTp/FckzVY8Evgr8qLhhlYbcsWl805OZlZtCCX53ROxK5y8BfhUR6yLiYWCvR+9Votx2+AeXPEj9zvoMozEz2zeFEnyDpOGSepI8rOPhnNd6FTes0nDUQUdx3NDjANixZwf3v3F/xhGZmbVfoQT/bWAOSTPNXRHxGoCkjwJvFj+00uCbnsysXLWa4CPiHuBwYHxE/EXOS3OAK4odWKm4fPz7zTT3LLqHHbt3ZBiNmVn7tdpNUtLUnPl8m7R51VHSUmAzsIekTX/CvoeYrQ8e/EGOGnQUS9YvYfPOzTz61qNMGj0p67DMzNrUaoIHbgdeSidoPv5M0I4EnzorItbuR2wlQRKXj7uc7z/zfSDpTeMEb2bloFAb/FRgEXAc8BZwc0R8Np0+1ynRlYjc7pJ3LryTPQ17MozGzKx9CrXBz4yIK4GPAkuAf5Y0O73I2l4BPChprqRp+TaQNE3SHElz6urq9in4zvKRER9heN/hANRtrePpt5/OOCIzs7a154lO24GNwCaScWh67sP+J0bEScAk4DpJZ7TcICJuiYgJETGhtrY0xzDroi5MGTeladljxJtZOSg0VMHZkm4B5gJnAf8SESdExAPt3XlEvJP+XAPMAE4+wHgz0+xRfgvuIKKiR0w2swpQqAb/MElCng30AD4l6UeNU1s7ltRHUr/GeeB84NUOiDkTZ446k4E9BwKwfONyXlz1YsYRmZkVVqgXzWcPcN9DgRlpF8uuwG8jYtYB7jMz3Wq6cemYS/n1vF8DSW+ak4aflHFUZmatKzRc8C9be609D92OiDdJBiirGFPHT21K8DMWzOA7Z38n44jMzFpX8CKrpFMl/amkg9Pl4yT9FqjKbiTnH3U+vbomw/C8Xvc6C9YuyDgiM7PWFbrI+k/Az4CPAfdK+g7wIPAcMLpzwistvbv1bnaTk3vTmFkpK1SDvxg4MSKuIrlA+mXglIj4l4jY3inRlSA/ys/MykWhBL+9MZFHxHrgjYhY2ilRlbBLxlxC1y7JpYvn332etze+nXFEZmb5FUrwR0q6q3ECjmixXJUG9hzI2Uec3bQ8c8HMDKMxM2tdoW6Sk1ss/3MxAyknU8dN5cElDwLJTU/Xf+T6jCMyM9tboW6ST3RmIOVk8rjJfP7ezxMETy57krVb1zKk95CswzIza6Y9Y9FYC8P6DuO0w04DoCEauGth1bZYmVkJc4LfT+5NY2alzgl+P+U+yu/BJQ+yecfmDKMxM9tboYusAEi6m2Rc91wbSZ7N+h/V2if+yEFHcsKwE3hp1Uvs3LOT+xffz8eP+XjWYZmZNWlPDf5NoB74aTptInnO6ph0uWo1G0J4fnufYGhm1jnak+BPi4hPRMTd6fRJ4MMRcR1Q1cMp5j7K79437mX77qr8MmNmJao9Cb5v7uiR6XzfdHFnUaIqE8fUHsMHDvoAAPU763nkzUcyjsjM7H3tSfBfA2ZLekzS48BTwNfTh3i0OqRwNZDE1HHv1+Ldm8bMSkmbCT4i7iMZPfLLwJeAsRFxb0RsiYgfFjvAUpfbm+bOhXeyu2F3htGYmb2vvd0kPwQcQ/IAj49L+lTxQiovJx96Mof0OwSAtVvX8vTyqhwq38xKUJsJXtKvge8DE4EPp9OE9hYgqUbSi5Lu2e8oS1gXdWHK2ClNy+5NY2aloj01+AnA6RHxVxFxfTp9cR/K+BIwf//CKw+5vWlmLJhBRMvbBszMOl97EvyrwLD92bmkESQPDvnP/Xl/uTjj8DMY1HMQAG9vepu5K+dmHJGZWfsS/BDgdUkP7Md48D8EvgE0tLaBpGmS5kiaU1dX187dlpZuNd24bOxlTctupjGzUtCeBH8jMAX4LsmY8I1TQZIuAdZERMHqbETcEhETImJCbW1tO8IpTR58zMxKTZtj0RzAuPCnA5dJugjoCfSX9Jv0TtiKc/5R59O7W2+27trKgrULmF83n/G147MOy8yqWKs1eEmz05+bJW3KmTZL2tTWjiPibyJiRESMAq4EHq3U5A7Qq1svJn1gUtOya/FmlrVWE3xETEx/9ouI/jlTv4jo33khlo/c3jRuhzezrLXrRqe0L/shkkY2TvtSSEQ8HhGX7F+I5ePi0RfTrUs3AOaunMvyjcszjsjMqll7bnS6HlgNPATcm04VedPSgRrQcwDnHHlO0/KM+W6mMbPstKcG3zj+zDER8cF0Oq7YgZUr96Yxs1LRngT/NskTnKwdJo+djBAATy1/irot5dm338zKX3uf6PS4pL+R9NXGqdiBlauhfYcyceREABqigbsWtveeMDOzjtWeBL+cpP29O9AvZ7JWNHuU3wL3pjGzbLTnRqebOiOQSnL5+Mv56oPJl5yH33yYTTs20b+He5aaWecqdKPTD9Ofd+eOQbOPY9FUpVEDR3HisBMB2LlnJ/e9cV/GEZlZNSpUg/91+vP7nRFIpZk6fiovrnoRSHrTXHnslRlHZGbVptCdrHPTn0/kmzovxPKU2w5/3xv3sX339gyjMbNq1J4bnUZLul3S65LebJw6I7hydnTt0YwZPAaA+p31PPzmwxlHZGbVpj29aH4O/ATYDZwF/Ar4TTGDqgSSmvem8dg0ZtbJ2pPge0XEI4AiYllE3EjylCZrQ+7gY3ctvIvdDbszjMbMqk17EvwOSV2ANyR9QdLlQN8ix1URJhwygUP7HQrAum3reGrZUxlHZGbVpL1j0fQGvgh8CPgk8OliBlUpuqiLx6Yxs8wUTPCSaoArIqI+IlZExGcj4mMR8WwnxVf2Lh/fvB2+IVp9PK2ZWYcqdKNT14jYA0zsxHgqzhmHn8FBvQ4C4J3N7zDn3TkZR2Rm1aJQDf6P6c8X07tXr5E0tXFqa8eSekr6o6SXJb0mqSqHPOjapSuXjb2sadljxJtZZ2lPG3xPYB1wNnAJcGn6sy07gLMj4njgBOBCSafsb6DlbOq4nEf5LbiDiMgwGjOrFoWGKjg4HRb4VSAgHeQ80WaGiiSL1aeL3dKpKjPbeUedR59ufdiyawuL1i1i/tr5HF17dNZhmVmFK1SDryHpDtmXZHjgvi2mNqXPcn0JWAM8FBHP5dlmmqQ5kubU1VXmwzF6du3JRaMvalr2TU9m1hnUWnOBpBci4qQOKUQaCMwAro+IV1vbbsKECTFnTmVehJz+ynQ+cccnADhp+EnMnTY344jMrBJImhsRE/K9VqgGrwKv7ZOI2AA8BlzYUfssNxePuZjuNd0BeGHlCyzdsDTbgMys4hVK8OccyI4l1aY1dyT1As4DFhzIPstZ/x79OffIc5uWZy6YmWE0ZlYNCg0X/N4B7ns48JikecDzJG3w9xzgPsuaBx8zs87Unm6S+yUi5kXEiRFxXEQcGxF/X6yyysVlYy+ji5KPfPby2ayuX51xRGZWyYqW4G1vB/c5mIkjkxuDg+CuhX7yoZkVjxN8J8u96cmDj5lZMTnBd7Ip46Y0zT/85sNs3L4xw2jMrJI5wXeywwcezoeGfwiAXQ27uO+N+zKOyMwqlRN8Bpr1plng3jRmVhxO8BnIfZTf/W/cz7Zd2zKMxswqlRN8BsbXjmfs4LEAbNm1hYfefCjjiMysEjnBZyS3Fu/eNGZWDE7wGclth79r4V3s2rMrw2jMrBI5wWdkwiETGNF/BADvbXuPJ5c9mXFEZlZpnOAzIqlZLd7NNGbW0ZzgM9SyHb4hGjKMxswqjRN8hiaOnMjgXoMBeHfzuzz/zvMZR2RmlcQJPkNdu3Rl8tjJTcseQtjMOpITfMYuH9/8rtbWHqFoZravnOAzdu6R59K3e/IM88XvLea1utcyjsjMKoUTfMZ6du3JRaMvalqeMd+9acysYxQtwUs6TNJjkl6X9JqkLxWrrHKXO0a8Bx8zs45SzBr8buBrEXE0cApwnaSji1he2bpo9EV0r+kOwEurXuKt9W9lHJGZVYJiPpN1ZUS8kM5vBuYDhxarvHLWr0c/zjvyvKZl3/RkZh2hU9rgJY0CTgSey/PaNElzJM2pq6vrjHBKkgcfM7OOVvQEL6kv8AfgyxGxqeXrEXFLREyIiAm1tbXFDqdkXTrmUroo+XU8vfxpVtevzjgiMyt3RU3wkrqRJPfbIsJXDwuo7VPLGYefAUAQ3LnwzowjMrNyV8xeNAJuBeZHxA+KVU4lafYoP9/VamYHqJg1+NOBa4CzJb2UThe19aZqlpvgH33rUTZs35BhNGZW7orZi2Z2RCgijouIE9LpvmKVVwkOG3AYEw6ZAMCuhl3cu+jejCMys3LmO1lLTO5NT+5NY2YHwgm+xOQOPnb/4vvZumtrhtGYWTlzgi8x44aMY/yQ8QBs3bWVB5c8mHFEZlaunOBLkB/lZ2YdwQm+BOXe1XrXwrvYtWdXhtGYWblygi9BJw0/iZEDRgKwYfsGnlj2RMYRmVk5coIvQZJ805OZHTAn+BKVm+BnLphJQzRkGI2ZlSMn+BI1ceREansng6+trF/Jcyv2GojTzKwgJ/gSVdOlhsvGXta07N40ZravnOBLWG5vmjvm30FEZBiNmZUbJ/gSds4R59Cvez8AlqxfwqtrXs04IjMrJ07wJaxH1x5cPObipmX3pjGzfeEEX+I8+JiZ7S8n+BI3afQketT0AODl1S/z5vo3M47IzMqFE3yJ69u9L+cfdX7T8oz5rsWbWfs4wZeBZne1LnA7vJm1TzGfyfozSWskuevHAbp07KXUqAaAZ95+hpWbV2YckZmVg2LW4H8BXFjE/VeNIb2HcMbhZwAQBHcuvDPjiMysHBTzmaxPAu8Va//VJvemJ/emMbP2yLwNXtI0SXMkzamrq8s6nJI1ZdyUpvlH33qU9dvWZxiNmZWDzBN8RNwSERMiYkJtbW3W4ZSsEf1HcPKhJwOwu2E39yy6J+OIzHDmigcAAAtGSURBVKzUZZ7grf38KD8z2xdO8GUktx1+1uJZbN21NcNozKzUFbOb5HTgGWCspBWSri1WWdVizOAxHF17NDTAti019L25H6O+dyy3zZuedWhmVoK6FmvHEXFVsfZdzcYMGsvrb62D26cTyyeybORspm1Izp1XH+eP3MzeV7QEb8Xx7Fuvwu3TYelZyYqlZ7F1+q1c2/Xj3LlwBsP6DmNon6EM6zus2XRwn4PpVtMt2+DNrFM5wZeZ1buWwPKJzVcun8iOLuv4/eu/L/jewb0GN0v6+U4EQ/sOZUjvIXSRL8+YlTsn+DIzstd4lo2c/X4NHmDkbNjZB3rUF3zvum3rWLdtHa/VvVZwuxrVcHCfg5sl/WF99j4RDOs7jAE9BiCpIw7NzDqYE3yZufnCG5i24Vq2Tr81qcmPnE3PKz/HV8/+EscOPYZV9atYVb+K1VtWN82vql9F3dY6GqKhXWXsiT2srF/Jyvq2x7zpUdOjXSeCYX2H0btb7wM9fDPbB07wZabxQuoNA69n+bb5jOw1npsv/G6bF1j3NOxh7da1zZJ+vhPBqvpVrN/e/rtkd+zZwbKNy1i2cVmb2/br3q950u+T/0RwcJ+D6V7Tvdl7b5s3nRtm3ZxzzDf4orJZG1RKD3KeMGFCzJkzJ+swqt6O3TtYs2VNmyeC1VtWU7+zcLPQ/hrca3BT0t+2awfPL1rK7v/+ddO3lu5XfJprTr2A00aeStcuXalRTfKzS01Rl7uoS6c0SVXjCc3HvH/HLGluREzI+5oTvB2I+p31rK5f3eaJYFX9Knbu2bl/hezoC9Pvan7dYdRjcNVlbV53KIYa1XTYiSPfuhUb3uH5xcvZk3NCq/n4NUwcO5qjBh+5VzyFTjii8MmoWO9t6/0t37to7WKeeP31Zifxrh+/hjOPPpoxQ0YXLKdcLVr7Bo+3OObeV13LLVfevE9J3gneMhcRbNi+oc2TwKr6VazZsqb59YIQ/MMOaMjp5tllF3yrB6h0/n47TImd0DqFjzkx6jEO//z1LP1G+x+jUSjBuw3eOoUkBvUaxKBegxhfO77gto3XCxqT/iem/yXr8vQc6stQ/uyESexu2M2e2JP8bEh+5lvXEcvtvVB9QLpvydsVlu5bil92VnzMieUTWb5tfocV4QRvJaemSw1D+w5laN+hHDf0OP7lsu8ybWvznkO9r7qW/2/qDzq9jTYiOvzE0XLdX834BmvznNAOqhnJ9y7+VvN4aP0bTFvfzov13rben++935z1f1mf55gH1RzGP1zwjYJllatvPfC9vMc8slfhCtC+cIK3kpe/59C+tVN2FEl0VdJ2Xiw79+zOe0L70eT/U7EXHQf0GMS0bXsf879O/seKPeaBPQ/Ke8w3X3hzh5XhBG9l4erjrqrYf/SWSumE1ll8zMU5Zl9kNTMrY4UusnrAETOzCuUEb2ZWoZzgzcwqlBO8mVmFcoI3M6tQJdWLRlId0PawhPkNAdZ2YDjlwMdc+arteMHHvK8Oj4jafC+UVII/EJLmtNZVqFL5mCtftR0v+Jg7kptozMwqlBO8mVmFqqQEf0vWAWTAx1z5qu14wcfcYSqmDd7MzJqrpBq8mZnlcII3M6tQFZXgJf2ZpNckNUiq2G5Wki6UtFDSYkl/nXU8xSbpZ5LWSGr/c8zKnKTDJD0m6fX0b/pLWcdUbJJ6SvqjpJfTY74p65g6g6QaSS9Kuqej911RCR54FZgKPJl1IMUiqQb4N2AScDRwlaSjs42q6H4BXJh1EJ1sN/C1iDgaOAW4rgp+zzuAsyPieOAE4EJJp2QcU2f4EtBxz+nLUVEJPiLmR8TCrOMospOBxRHxZkTsBP4LmJxxTEUVEU8C72UdR2eKiJUR8UI6v5kkARyabVTFFYnGJ2x3S6eK7gUiaQRwMfCfxdh/RSX4KnEo8HbO8goq/B+/2kkaBZwIPJdtJMWXNle8BKwBHoqISj/mHwLfAIryNPeyS/CSHpb0ap6pomuxVp0k9QX+AHw5IjZlHU+xRcSeiDgBGAGcLOnYrGMqFkmXAGsiYm6xyii7Z7JGxLlZx5Cxd4DDcpZHpOuswkjqRpLcb4uIO7KOpzNFxAZJj5Fce6nUi+unA5dJugjoCfSX9JuI+GRHFVB2NXjjeWC0pCMkdQeuBO7KOCbrYJIE3ArMj4gfZB1PZ5BUK2lgOt8LOA9YkG1UxRMRfxMRIyJiFMn/8aMdmdyhwhK8pMslrQBOBe6V9EDWMXW0iNgNfAF4gOTC239HxGvZRlVckqYDzwBjJa2QdG3WMXWC04FrgLMlvZROF2UdVJENBx6TNI+kIvNQRHR418Fq4qEKzMwqVEXV4M3M7H1O8GZmFcoJ3sysQjnBm5lVKCd4M7MK5QRvRSepvu2tWn3vF9JRM0PSkJz1kvSj9LV5kk7KeW1448h8kganozLWS/pxnv3/taSrJd0o6ev7G2eB+D+Tr9wO3P8EST8q8HqtpFnFKt9KmxO8lbqngXOBZS3WTwJGp9M04Cc5r30V+Gk6vx34FtBa8r4AeLCjgu1sETEnIr5Y4PU6YKWk0zsxLCsRTvDWadJa9z+lYwe9IumKdH0XSf8uaYGkhyTdJ+lPASLixYhYmmd3k4FfpSMQPgsMlDQ8fe1jwKz0/VsiYjZJom8ZT3+ge5oEc9f/haTn03HJ/yCpd7r+F5J+IulZSW9KOjMdq36+pF/kvP+zkhZJ+iPJDUuN6y+V9Fw69vfDkobmiWmUpKckvZBOp6XrL5f0SPoZDk/3PyyNofHbykdzbop6UVK/dLczgavb+v1Y5XGCt840lWSc7+NJauX/lCblqcAokvHtryG5E7kteUfVlHQEsD4idrRjH+cCj+RZf0dEfDgdl3w+kHvn7KA0vq+QDBHx/wLHAB+UdEJ6PDeRJPaJ6TE1mg2cEhEnkgzz/I08Za8BzouIk4ArgB8BRMQMYCVwHcm3k7+LiFUt3vt14Lp0sK4/Abal6+eky1Zlym6wMStrE4HpEbEHWC3pCeDD6frfR0QDsCodZGp/DQfq2twqcSHw8zzrj5X0HWAg0JdkWIhGd0dESHoFWB0RrwBIeo3kJDUKeLzxW4Gk3wFj0veOAH6XngS6A2/lKbsb8GNJJwB7ct4LcD3JwFvPRsT0PO99GviBpNtITlIr0vVrgENa/RSsYrkGb+WqtVE1t5GMzNceJwN/zLP+F8AXIuKDJLXx3P01fjNoyJlvXG6rwvSvwI/T/f5lK3F+BVhN8i1nAsmJoNGItJyhkvb6342IfwT+HOgFPC1pXPpST96vzVsVcYK3zvQUcIWShzrUAmeQJNingY+lbfFDgTPbsa+7gE+lbdKnABsjYiWwiKQWXZCkY4AF6beJlvqRXJjsxr63XT8HfDTtvdMN+LOc1wbw/tDOn27l/QOAlem3mWuAmjTersDPgKtImo2+mueYjoqIVyLi/5IM1tWY4MdQuUPuWgFuorHONIOk/fplkkexfSMiVkn6A3AO8DpJu/oLwEYASV8kaaseBsyTdF9E/DlwH3ARsBjYCnwWkouqkpZI+kBELE73sRToD3SXNAU4n6QXTmvdB79Fkqjr0p/9WtluLxGxUtKNJKNfbgBeynn5RuD3ktYDjwJH5NnFvwN/kPSpNL4t6fq/BZ6KiNmSXgael3Rvi/d+WdJZJLX814D70/VnAS23tSrg0SStJEjqGxH1kgaT1OpPz3MRsb37uhz4UER8s8A2DwGfSmv9FU3Sk8DkiFifdSzWuVyDt1Jxj5KHPXQH/mF/kzskPU7SE0Whbc7b3/2Xk7Qp7AdO7tXJNXgzswrli6xmZhXKCd7MrEI5wZuZVSgneDOzCuUEb2ZWof5/RVzcJQhbBZQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Finding minimum validation MSE and corresponding index in validationMSE array\n",
        "'''\n",
        "minValidationRMSE = min(validationRMSE)   #Find out the minimum validation MSE\n",
        "for i in range(0,numLamdaVals): #Find the array index corresponding to minimum validation MSE\n",
        "  if(validationRMSE[i] == minValidationRMSE):\n",
        "    minValidationMSEindex = i    \n",
        "    break\n",
        "optimumLamda = lamdaArray[minValidationMSEindex] #Optimum Lamda corresponds to lamda value at mimimum Validation MSE Index"
      ],
      "metadata": {
        "id": "TyTzpeHxEaUI"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Plotting Validation RMSE vs log10(1/lamda)\n",
        "'''\n",
        "print('Valdation RMSE:',validationRMSE)\n",
        "print('1/lamda Array: ',1./lamdaArray)\n",
        "print('Best lamda which gives min. Validation RMSE = ',optimumLamda)\n",
        "print('Validation RMSE for best lamda = ',validationRMSE[minValidationMSEindex]) # Validation MSE corresponding to best lamda\n",
        "print('Validation NRMSE for best lamda = ',validationRMSE[minValidationMSEindex]/np.std(t_val))  # Validation NMSE corresponding to best lamda\n",
        "plt.figure()\n",
        "plt.title('Validation RMSE Vs log10(1/lamda) plot')\n",
        "plt.xlabel('1/lamda axis (in log10)')\n",
        "plt.ylabel('Validation RMSE')\n",
        "#Since consecutive lamda values vary by large gaps we have plotted them on log scale on x axis\n",
        "plt.plot(np.log10(1./lamdaArray),validationRMSE,color='red', linestyle='-', linewidth = 3,marker='o', markerfacecolor='red', markersize=6)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "7e6ba39f-365b-4dff-9925-54babe36c235",
        "id": "vKsFR4XAEw5U"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valdation RMSE: [9.40565994 0.84644062 0.5308134  0.48420429 0.48719127 0.4876578 ]\n",
            "1/lamda Array:  [1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04]\n",
            "Best lamda which gives min. Validation RMSE =  0.01\n",
            "Validation RMSE for best lamda =  0.48420429133526205\n",
            "Validation NRMSE for best lamda =  0.3923666343150988\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Using optimum lamda we will run gradient descent on training data and find the best w vector\n",
        "'''\n",
        "w = np.ones(x_train.shape[1]+1) #Weights vector has one dimension more than the number of features in x matrix\n",
        "for i in range(maxiter): #This for loop finds the array index corresponding to minimum Validation MSE\n",
        "  grad = L1_Gradient(x_train, t_train, w, optimumLamda) #find the gradient for L1 gradient\n",
        "  temp_w = w -  L*grad  #Gradient descent\n",
        "  w = temp_w\n",
        "  L2_loss[i] =  L2_Loss(x_train, t_train, w, optimumLamda) #L2_Loss function\n",
        "\n",
        "print('Best weight vector for optimum lamda = ',w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82782a8e-f828-4f6b-c927-60e59ec8e985",
        "id": "nVVKhSLUE85N"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weight vector for optimum lamda =  [ 0.12680125  0.01947031  0.13547737 -0.03108436  0.6263373   0.052992\n",
            " -0.10063052  0.08023213 -0.13458817 -0.02803836 -0.0563221  -0.10138192\n",
            " -0.0262361   0.06613126 -0.00183205  0.00065672 -0.02246    -0.03263323\n",
            " -0.05975272  0.06745347  0.027235   -0.02959989]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations for Part 2 Question 4:**\n",
        "\n",
        "1) For** Learning Rate L = 1**:\n",
        "\n",
        "Training RMSE: [inf inf inf inf inf inf]\n",
        "\n",
        "1/lamda Array:  [1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04]\n",
        "\n",
        "Valdation RMSE: [inf inf inf inf inf inf]\n",
        "\n",
        "Clearly learning rate of 1 is not an optimum choice\n",
        "\n",
        "2)For **Learning Rate L = 0.1**:\n",
        "\n",
        "Training RMSE: [8.14217193 0.70561497 0.4854272  0.45295417 0.45186751 0.45185433]\n",
        "\n",
        "1/lamda Array: [1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04]\n",
        "\n",
        "Valdation RMSE: [9.40565994 0.84644062 0.5308134  0.48420429 0.48719127 0.4876578 ](Min. validation MSE occurs at: **lamda = 0.01**)\n",
        "\n",
        "3)For **Learning Rate L = 0.01**: \n",
        "\n",
        "Training RMSE:[0.98130594 0.72470278 0.48844081 0.46700743 0.46721147 0.46728953]\n",
        "\n",
        "1/lamda Array: [1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04] \n",
        "\n",
        "Valdation RMSE: [1.29992238 1.0202405  0.48901306 0.45705873 0.45877743 0.45902394] (Min. validation MSE occurs at: **lamda =0.01**)\n",
        "\n",
        "Therefore, the minimum validation RMSE occurs at lamda = 0.01. Learning Rate of 0.1 and 0.01 have approximately same validation RMSE for lamda = 0.1. Since Learning rate of 0.1 needs lesser number of iterations to converge than learning rate of 0.01 , learning rate of 0.1 will be optimum.\n",
        "\n"
      ],
      "metadata": {
        "id": "TnPsIbldHcUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2 Question 5 Starts \"best lamda for the pseudo-inv method\"**"
      ],
      "metadata": {
        "id": "maey9Brjkz6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Initialization of different arrays and variables for TASK 3,4 and 5\n",
        "'''\n",
        "lamda = 10 #Assume initial lamda parameter\n",
        "numLamdaVals = 6  #define the number of lamda values you are going to test\n",
        "lamdaArray = np.zeros(numLamdaVals)  #An array to store the different lamda values\n",
        "trainingRMSE = np.zeros(numLamdaVals)  #size of training MSE array = number of lamda values\n",
        "validationRMSE = np.zeros(numLamdaVals)  #An array to store validation MSE "
      ],
      "metadata": {
        "id": "oUWBgb-HlJ5g"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Training the model using gradient descent for each lamda\n",
        "'''\n",
        "for lCount in range(0,numLamdaVals):  #This for loop is to train model for each lamda value\n",
        "  w = Pseudo_Inverse (x_train, t_train, lamda)  #Find the pseudo inverse to get w vector\n",
        "  lamdaArray[lCount] = lamda  #lamda array stores the lamda value\n",
        "  trainingRMSE[lCount] = np.sqrt(MSE_Loss(x_train, t_train, w, lamda))  #for each lamda find training MSE\n",
        "  validationRMSE[lCount] = np.sqrt(MSE_Loss(x_val,t_val,w,lamda)) #for each lamda find validation MSE\n",
        "  lamda = lamda/10  # Update lamda by dividing it by a factor of 10"
      ],
      "metadata": {
        "id": "bJwQa-kcl148"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Finding minimum training RMSE and corresponding index in trainingRMSE array\n",
        "'''\n",
        "minTrainRMSE = min(trainingRMSE)  #Find out the minimum training MSE\n",
        "print('Min. Training RMSE =',minTrainRMSE)  #Print the minimum training MSE\n",
        "for i in range(0,numLamdaVals): #This for loop finds the array index corresponding to minimum Training MSE\n",
        "  if(trainingRMSE[i] == minTrainRMSE):\n",
        "    minTrainMSEindex = i    \n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkMhjKShm1Ow",
        "outputId": "d6ceb045-c4f4-41a6-d6e1-a27bb0fbd803"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min. Training RMSE = 0.45185313890878837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Plotting Training RMSE vs log10(1/lamda)\n",
        "''' \n",
        "print('Training RMSE:',trainingRMSE)\n",
        "print('1/lamda Array: ',1./lamdaArray)\n",
        "plt.figure()\n",
        "plt.title('Training RMSE Vs log10(1/lamda) plot')\n",
        "plt.xlabel('log10(1/lamda axis)')\n",
        "plt.ylabel('Training RMSE')\n",
        "#Since consecutive lamda values vary by large gaps we have plotted them on log scale on x axis\n",
        "plt.plot(np.log10(1./lamdaArray),trainingRMSE,color='green', linestyle='-', linewidth = 3,marker='o', markerfacecolor='blue', markersize=6)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "54ab8121-1ecc-4028-b4ab-941772e7275a",
        "id": "MViDmQqWnWNe"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RMSE: [0.45187014 0.45185332 0.45185314 0.45185314 0.45185314 0.45185314]\n",
            "1/lamda Array:  [1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Finding minimum validation MSE and corresponding index in validationMSE array\n",
        "'''\n",
        "minValidationRMSE = min(validationRMSE)   #Find out the minimum validation MSE\n",
        "for i in range(0,numLamdaVals): #\n",
        "  if(validationRMSE[i] == minValidationRMSE):\n",
        "    minValidationMSEindex = i    \n",
        "    break\n",
        "optimumLamda = lamdaArray[minValidationMSEindex] #Optimum Lamda corresponds to lamda value at mimimum Validation MSE Index"
      ],
      "metadata": {
        "id": "ksgZLX5OngUU"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Plotting Validation RMSE vs 1/lamda\n",
        "'''\n",
        "print('Valdation RMSE:',validationRMSE)\n",
        "print('1/lamda Array: ',1./lamdaArray)\n",
        "print('Best lamda which gives min. Validation RMSE = ',optimumLamda)\n",
        "print('Validation RMSE for best lamda = ',validationRMSE[minValidationMSEindex]) # Validation MSE corresponding to best lamda\n",
        "print('Validation NRMSE for best lamda = ',validationRMSE[minValidationMSEindex]/np.std(t_val))  # Validation NMSE corresponding to best lamda\n",
        "plt.figure()\n",
        "plt.title('Validation RMSE Vs log10(1/lamda) plot')\n",
        "plt.xlabel('1/lamda axis (in log10)')\n",
        "plt.ylabel('Validation RMSE')\n",
        "#Since consecutive lamda values vary by large gaps we have plotted them on log scale on x axis\n",
        "plt.plot(np.log10(1./lamdaArray),validationRMSE,color='red', linestyle='-', linewidth = 3,marker='o', markerfacecolor='red', markersize=6)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "d3abccc8-298f-4ad5-d713-d98fb1e8788c",
        "id": "1TLcwT-anqgs"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valdation RMSE: [0.4870014  0.48775813 0.4878367  0.48784459 0.48784538 0.48784546]\n",
            "1/lamda Array:  [1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04]\n",
            "Best lamda which gives min. Validation RMSE =  10.0\n",
            "Validation RMSE for best lamda =  0.4870014034737439\n",
            "Validation NRMSE for best lamda =  0.39463322611367935\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations for Part 2 Question 5:**\n",
        "Valdation RMSE: [0.4870014  0.48775813 0.4878367  0.48784459 0.48784538 0.48784546]\n",
        "\n",
        "1/lamda Array:  [1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04]\n",
        "\n",
        "Best lamda which gives min. Validation RMSE =  10.0\n",
        "\n",
        "Therefore, the minimum validation RMSE occurs at lamda = 10. This method is not computationally efficient and hence generally not used for gradient descent. In this method as we decrease lamda we get a very small increase in RMSE.\n",
        "\n",
        "**Conclusion:**\n",
        "The best lamda = 0.1 it gives the minimum validation RMSE in case of **MSE+L2_loss(w)** model. We will use this model to predict the output from our test data.\n"
      ],
      "metadata": {
        "id": "pss7qauyrz8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2 Question 6 \"Running the gradient descent on test.csv\"**"
      ],
      "metadata": {
        "id": "c_5aJkf1xOoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Optimum Learning rate, lamda which give min validation NMSE for the L2_loss, L1_loss are used to predict the putput for test data\n",
        "Minimum validation RMSE is obtained for gradient descent using L2 Loss function \n",
        "for optimum learning rate = 0.1 and lamda = 0.1\n",
        "'''\n",
        "\n",
        "'''\n",
        "NOTE: After training, our learning algorithm has learnt to deal with the data in scaled form, so we have to normalize our test data with the \n",
        "normalizing parameters used for training data.\n",
        "Source: https://datascience.stackexchange.com/questions/27615/should-we-apply-normalization-to-test-data-as-well#:~:text=Yes%20you%20need%20to%20apply,is%20part%20of%20the%20representation.\n",
        "Both answers given on this link answer this. And this method gives very accurate results.\n",
        "'''\n",
        "x = pd.read_csv('https://www.ee.iitb.ac.in/~asethi/Dump/TempTest.csv')  #Read the test data from given link\n",
        "x = (x-inputTrainingMean)/inputTrainingSd #Normalize the test data using training mean and std dev\n",
        "#h_theta is the predicted output by our model\n",
        "h_theta = Prediction (x, wTest) #Predict the output using wTest from MSE + L2_loss function as it gives minimum RMSE error\n",
        "h_theta = h_theta*targetTrainingSd + targetTrainingMean #targetTrainingSd and targetTrainingMean were defined initially when we read training data from TempTrain.csv\n",
        "#To remove normalization from the estimated vector h_theta by multiplying the training target standard deviation and adding target training mean to predicted result\n",
        "print(h_theta)  \n",
        "df = pd.DataFrame(h_theta)  #Convert the array into a pandas data frame in order to write it as a .csv file\n",
        "#df.to_csv('213070003_213070014_1.csv',header=['Next_Tmax'], index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5gC2VguykKc",
        "outputId": "e8a22e94-fa03-46e9-a103-b74eb610432e"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[27.50469838 29.46376179 29.65101026 ... 27.81126658 27.88646396\n",
            " 27.76888317]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**... Part 2 ends.**\n",
        "\n",
        "1. Write the name or roll no.s of friends from outside your group with whom you discussed the assignment here (no penalty for mere discussion without copying code) :  Satyabrata Sahu (Roll no: 213070015) \n",
        "\n",
        "2. Write the links of sources on the internet referred here (no penalty for mere consultation without copying code): \n",
        "\n",
        "https://www.askpython.com/python/examples/split-data-training-and-testing-set\n",
        "\n",
        "https://machinelearningmastery.com/how-to-improve-neural-network-stability-and-modeling-performance-with-data-scaling/\n",
        "\n",
        "https://stats.stackexchange.com/questions/111467/is-it-necessary-to-scale-the-target-value-in-addition-to-scaling-features-for-re#:~:text=Yes%2C%20you%20do%20need%20to%20scale%20the%20target%20variable.\n",
        "\n",
        "Need to normalize the test data explained here:\n",
        "https://datascience.stackexchange.com/questions/27615/should-we-apply-normalization-to-test-data-as-well#:~:text=Yes%20you%20need%20to%20apply,is%20part%20of%20the%20representation."
      ],
      "metadata": {
        "id": "X5xoNrdBYCGc"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "213070003_213070014_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}